{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train_x',\n",
       " 'train_y',\n",
       " '__header__',\n",
       " '__globals__',\n",
       " '__version__',\n",
       " 'annotations',\n",
       " 'test_y',\n",
       " 'test_x']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.io import loadmat\n",
    "annots = loadmat('sat-4-full.mat')\n",
    "annots2 = loadmat('test_x_only.mat')\n",
    "annots.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__version__', 'test_x', '__header__', '__globals__']"
      ]
     },
     "execution_count": 460,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annots2.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[130, 164, 120, ..., 145, 151, 158],\n",
       "         [120, 139, 114, ..., 141, 134, 155],\n",
       "         [113, 111, 114, ..., 125, 126, 145],\n",
       "         [143, 196, 132, ..., 159, 150, 202]],\n",
       "\n",
       "        [[137, 171, 111, ..., 147, 142, 163],\n",
       "         [134, 147, 105, ..., 140, 126, 161],\n",
       "         [127, 122, 100, ..., 122, 118, 151],\n",
       "         [159, 201, 128, ..., 159, 143, 209]],\n",
       "\n",
       "        [[133, 168,  61, ..., 146, 130, 137],\n",
       "         [126, 139,  45, ..., 136, 116, 133],\n",
       "         [115, 114,  25, ..., 122, 104, 109],\n",
       "         [152, 197,  86, ..., 161, 138, 182]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[147, 171, 123, ..., 162, 123, 124],\n",
       "         [129, 139, 117, ..., 149, 107, 117],\n",
       "         [116, 109, 117, ..., 127,  96, 106],\n",
       "         [159, 198, 155, ..., 169, 130, 159]],\n",
       "\n",
       "        [[148, 171,  93, ..., 169, 132, 137],\n",
       "         [131, 140,  82, ..., 154, 117, 140],\n",
       "         [121, 112,  63, ..., 133, 106, 128],\n",
       "         [158, 197, 132, ..., 169, 138, 176]],\n",
       "\n",
       "        [[144, 172,  81, ..., 169, 137, 124],\n",
       "         [126, 142,  82, ..., 150, 123, 124],\n",
       "         [119, 116,  69, ..., 130, 113, 113],\n",
       "         [153, 197, 141, ..., 168, 142, 167]]],\n",
       "\n",
       "\n",
       "       [[[134, 165, 121, ..., 147, 130, 138],\n",
       "         [124, 144, 115, ..., 145, 110, 134],\n",
       "         [117, 115, 112, ..., 125,  98, 120],\n",
       "         [143, 197, 139, ..., 160, 132, 178]],\n",
       "\n",
       "        [[136, 169, 100, ..., 147, 130, 152],\n",
       "         [133, 142,  95, ..., 145, 113, 149],\n",
       "         [127, 115,  89, ..., 125, 102, 134],\n",
       "         [161, 197, 131, ..., 160, 135, 193]],\n",
       "\n",
       "        [[129, 165,  79, ..., 152, 132, 176],\n",
       "         [124, 138,  69, ..., 144, 120, 173],\n",
       "         [112, 110,  57, ..., 126, 111, 157],\n",
       "         [150, 196, 122, ..., 159, 138, 221]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[146, 174, 114, ..., 157, 122, 102],\n",
       "         [130, 145, 107, ..., 147, 106,  94],\n",
       "         [118, 118,  88, ..., 126,  96,  77],\n",
       "         [161, 199, 125, ..., 169, 127, 137]],\n",
       "\n",
       "        [[148, 184, 133, ..., 163, 133, 141],\n",
       "         [131, 160, 123, ..., 154, 118, 140],\n",
       "         [123, 136, 105, ..., 130, 108, 128],\n",
       "         [158, 208, 160, ..., 170, 136, 183]],\n",
       "\n",
       "        [[151, 176,  81, ..., 165, 139, 108],\n",
       "         [131, 147,  82, ..., 151, 124, 105],\n",
       "         [124, 122,  63, ..., 130, 114,  87],\n",
       "         [162, 199, 140, ..., 170, 144, 151]]],\n",
       "\n",
       "\n",
       "       [[[141, 163, 116, ..., 149, 137, 130],\n",
       "         [131, 136, 114, ..., 147, 122, 125],\n",
       "         [126, 109, 107, ..., 127, 110, 108],\n",
       "         [154, 193, 133, ..., 162, 141, 171]],\n",
       "\n",
       "        [[137, 164,  94, ..., 145, 124, 137],\n",
       "         [132, 139,  87, ..., 142, 110, 134],\n",
       "         [125, 109,  81, ..., 127,  99, 120],\n",
       "         [164, 195, 122, ..., 161, 133, 184]],\n",
       "\n",
       "        [[132, 175,  86, ..., 150, 126, 160],\n",
       "         [126, 152,  78, ..., 147, 113, 158],\n",
       "         [113, 124,  77, ..., 130, 105, 143],\n",
       "         [152, 202, 136, ..., 160, 135, 207]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[156, 169, 159, ..., 153, 122, 123],\n",
       "         [140, 136, 156, ..., 144, 108, 116],\n",
       "         [130, 109, 151, ..., 122,  97, 103],\n",
       "         [170, 193, 180, ..., 168, 128, 162]],\n",
       "\n",
       "        [[144, 170, 151, ..., 148, 134, 145],\n",
       "         [126, 142, 142, ..., 141, 120, 141],\n",
       "         [119, 115, 138, ..., 124, 109, 132],\n",
       "         [156, 195, 178, ..., 170, 137, 188]],\n",
       "\n",
       "        [[151, 186,  70, ..., 145, 149, 152],\n",
       "         [132, 159,  65, ..., 137, 134, 150],\n",
       "         [125, 140,  44, ..., 126, 123, 137],\n",
       "         [165, 207, 112, ..., 168, 150, 199]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[170, 173, 125, ..., 200, 170, 148],\n",
       "         [153, 147, 113, ..., 184, 147, 145],\n",
       "         [143, 122,  93, ..., 158, 135, 127],\n",
       "         [188, 200, 134, ..., 185, 159, 185]],\n",
       "\n",
       "        [[157, 174, 204, ..., 196, 156, 125],\n",
       "         [135, 149, 205, ..., 179, 131, 114],\n",
       "         [121, 126, 216, ..., 159, 119, 100],\n",
       "         [174, 201, 219, ..., 183, 149, 158]],\n",
       "\n",
       "        [[166, 170, 217, ..., 189, 151, 145],\n",
       "         [146, 144, 229, ..., 173, 129, 138],\n",
       "         [135, 120, 237, ..., 150, 111, 122],\n",
       "         [181, 198, 230, ..., 178, 147, 187]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[154, 159, 220, ..., 158, 109, 117],\n",
       "         [144, 129, 235, ..., 149, 108, 120],\n",
       "         [131,  94, 235, ..., 133,  98, 113],\n",
       "         [182, 191, 234, ..., 169, 140, 155]],\n",
       "\n",
       "        [[148, 159, 222, ..., 150, 106,  84],\n",
       "         [138, 128, 233, ..., 142, 101,  82],\n",
       "         [131,  95, 237, ..., 127,  93,  77],\n",
       "         [174, 191, 234, ..., 164, 138, 119]],\n",
       "\n",
       "        [[135, 170, 220, ..., 140, 109,  93],\n",
       "         [125, 141, 229, ..., 142, 104,  91],\n",
       "         [119, 115, 233, ..., 121,  95,  84],\n",
       "         [157, 199, 231, ..., 165, 142, 129]]],\n",
       "\n",
       "\n",
       "       [[[177, 170, 161, ..., 195, 155, 146],\n",
       "         [159, 145, 159, ..., 182, 131, 148],\n",
       "         [150, 115, 155, ..., 157, 113, 133],\n",
       "         [193, 200, 181, ..., 180, 147, 196]],\n",
       "\n",
       "        [[163, 164, 225, ..., 197, 138, 147],\n",
       "         [144, 136, 233, ..., 180, 110, 142],\n",
       "         [133, 108, 237, ..., 156,  88, 127],\n",
       "         [182, 195, 233, ..., 179, 133, 192]],\n",
       "\n",
       "        [[163, 174, 216, ..., 190, 142, 174],\n",
       "         [144, 151, 224, ..., 175, 120, 172],\n",
       "         [131, 127, 227, ..., 152, 100, 158],\n",
       "         [181, 202, 228, ..., 178, 140, 226]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[145, 170, 222, ..., 163, 108, 101],\n",
       "         [138, 141, 231, ..., 152, 103, 102],\n",
       "         [133, 112, 233, ..., 135,  95,  94],\n",
       "         [180, 198, 231, ..., 168, 136, 132]],\n",
       "\n",
       "        [[128, 170, 225, ..., 153, 109,  99],\n",
       "         [121, 144, 233, ..., 150, 103,  98],\n",
       "         [109, 116, 237, ..., 130,  95,  93],\n",
       "         [161, 200, 232, ..., 165, 138, 127]],\n",
       "\n",
       "        [[140, 162, 225, ..., 147, 110, 106],\n",
       "         [133, 134, 231, ..., 146, 104, 104],\n",
       "         [128, 105, 235, ..., 126,  95,  97],\n",
       "         [165, 192, 231, ..., 163, 140, 134]]],\n",
       "\n",
       "\n",
       "       [[[158, 170, 217, ..., 202, 150, 120],\n",
       "         [138, 140, 227, ..., 188, 128, 117],\n",
       "         [120, 117, 229, ..., 151, 100,  99],\n",
       "         [172, 201, 230, ..., 177, 145, 163]],\n",
       "\n",
       "        [[175, 171, 220, ..., 196, 143, 105],\n",
       "         [162, 145, 224, ..., 183, 127,  97],\n",
       "         [148, 122, 227, ..., 153,  97,  76],\n",
       "         [195, 202, 226, ..., 176, 145, 148]],\n",
       "\n",
       "        [[168, 170, 219, ..., 187, 138, 173],\n",
       "         [152, 144, 225, ..., 173, 119, 170],\n",
       "         [140, 118, 229, ..., 148,  93, 154],\n",
       "         [186, 200, 228, ..., 179, 135, 221]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[124, 169, 220, ..., 162, 116, 115],\n",
       "         [120, 141, 231, ..., 153, 105, 116],\n",
       "         [106, 108, 235, ..., 131,  99, 108],\n",
       "         [169, 196, 232, ..., 167, 136, 145]],\n",
       "\n",
       "        [[129, 164, 225, ..., 155, 112,  82],\n",
       "         [127, 140, 225, ..., 150, 104,  83],\n",
       "         [115, 111, 227, ..., 130,  96,  69],\n",
       "         [173, 195, 230, ..., 165, 137, 113]],\n",
       "\n",
       "        [[137, 174, 194, ..., 150, 112, 131],\n",
       "         [131, 152, 183, ..., 145, 105, 136],\n",
       "         [131, 127, 186, ..., 131,  96, 126],\n",
       "         [172, 202, 206, ..., 163, 138, 165]]]], dtype=uint8)"
      ]
     },
     "execution_count": 461,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annots2['test_x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[130, 164, 120, ..., 145, 151, 158],\n",
       "         [120, 139, 114, ..., 141, 134, 155],\n",
       "         [113, 111, 114, ..., 125, 126, 145],\n",
       "         [143, 196, 132, ..., 159, 150, 202]],\n",
       "\n",
       "        [[137, 171, 111, ..., 147, 142, 163],\n",
       "         [134, 147, 105, ..., 140, 126, 161],\n",
       "         [127, 122, 100, ..., 122, 118, 151],\n",
       "         [159, 201, 128, ..., 159, 143, 209]],\n",
       "\n",
       "        [[133, 168,  61, ..., 146, 130, 137],\n",
       "         [126, 139,  45, ..., 136, 116, 133],\n",
       "         [115, 114,  25, ..., 122, 104, 109],\n",
       "         [152, 197,  86, ..., 161, 138, 182]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[147, 171, 123, ..., 162, 123, 124],\n",
       "         [129, 139, 117, ..., 149, 107, 117],\n",
       "         [116, 109, 117, ..., 127,  96, 106],\n",
       "         [159, 198, 155, ..., 169, 130, 159]],\n",
       "\n",
       "        [[148, 171,  93, ..., 169, 132, 137],\n",
       "         [131, 140,  82, ..., 154, 117, 140],\n",
       "         [121, 112,  63, ..., 133, 106, 128],\n",
       "         [158, 197, 132, ..., 169, 138, 176]],\n",
       "\n",
       "        [[144, 172,  81, ..., 169, 137, 124],\n",
       "         [126, 142,  82, ..., 150, 123, 124],\n",
       "         [119, 116,  69, ..., 130, 113, 113],\n",
       "         [153, 197, 141, ..., 168, 142, 167]]],\n",
       "\n",
       "\n",
       "       [[[134, 165, 121, ..., 147, 130, 138],\n",
       "         [124, 144, 115, ..., 145, 110, 134],\n",
       "         [117, 115, 112, ..., 125,  98, 120],\n",
       "         [143, 197, 139, ..., 160, 132, 178]],\n",
       "\n",
       "        [[136, 169, 100, ..., 147, 130, 152],\n",
       "         [133, 142,  95, ..., 145, 113, 149],\n",
       "         [127, 115,  89, ..., 125, 102, 134],\n",
       "         [161, 197, 131, ..., 160, 135, 193]],\n",
       "\n",
       "        [[129, 165,  79, ..., 152, 132, 176],\n",
       "         [124, 138,  69, ..., 144, 120, 173],\n",
       "         [112, 110,  57, ..., 126, 111, 157],\n",
       "         [150, 196, 122, ..., 159, 138, 221]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[146, 174, 114, ..., 157, 122, 102],\n",
       "         [130, 145, 107, ..., 147, 106,  94],\n",
       "         [118, 118,  88, ..., 126,  96,  77],\n",
       "         [161, 199, 125, ..., 169, 127, 137]],\n",
       "\n",
       "        [[148, 184, 133, ..., 163, 133, 141],\n",
       "         [131, 160, 123, ..., 154, 118, 140],\n",
       "         [123, 136, 105, ..., 130, 108, 128],\n",
       "         [158, 208, 160, ..., 170, 136, 183]],\n",
       "\n",
       "        [[151, 176,  81, ..., 165, 139, 108],\n",
       "         [131, 147,  82, ..., 151, 124, 105],\n",
       "         [124, 122,  63, ..., 130, 114,  87],\n",
       "         [162, 199, 140, ..., 170, 144, 151]]],\n",
       "\n",
       "\n",
       "       [[[141, 163, 116, ..., 149, 137, 130],\n",
       "         [131, 136, 114, ..., 147, 122, 125],\n",
       "         [126, 109, 107, ..., 127, 110, 108],\n",
       "         [154, 193, 133, ..., 162, 141, 171]],\n",
       "\n",
       "        [[137, 164,  94, ..., 145, 124, 137],\n",
       "         [132, 139,  87, ..., 142, 110, 134],\n",
       "         [125, 109,  81, ..., 127,  99, 120],\n",
       "         [164, 195, 122, ..., 161, 133, 184]],\n",
       "\n",
       "        [[132, 175,  86, ..., 150, 126, 160],\n",
       "         [126, 152,  78, ..., 147, 113, 158],\n",
       "         [113, 124,  77, ..., 130, 105, 143],\n",
       "         [152, 202, 136, ..., 160, 135, 207]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[156, 169, 159, ..., 153, 122, 123],\n",
       "         [140, 136, 156, ..., 144, 108, 116],\n",
       "         [130, 109, 151, ..., 122,  97, 103],\n",
       "         [170, 193, 180, ..., 168, 128, 162]],\n",
       "\n",
       "        [[144, 170, 151, ..., 148, 134, 145],\n",
       "         [126, 142, 142, ..., 141, 120, 141],\n",
       "         [119, 115, 138, ..., 124, 109, 132],\n",
       "         [156, 195, 178, ..., 170, 137, 188]],\n",
       "\n",
       "        [[151, 186,  70, ..., 145, 149, 152],\n",
       "         [132, 159,  65, ..., 137, 134, 150],\n",
       "         [125, 140,  44, ..., 126, 123, 137],\n",
       "         [165, 207, 112, ..., 168, 150, 199]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[170, 173, 125, ..., 200, 170, 148],\n",
       "         [153, 147, 113, ..., 184, 147, 145],\n",
       "         [143, 122,  93, ..., 158, 135, 127],\n",
       "         [188, 200, 134, ..., 185, 159, 185]],\n",
       "\n",
       "        [[157, 174, 204, ..., 196, 156, 125],\n",
       "         [135, 149, 205, ..., 179, 131, 114],\n",
       "         [121, 126, 216, ..., 159, 119, 100],\n",
       "         [174, 201, 219, ..., 183, 149, 158]],\n",
       "\n",
       "        [[166, 170, 217, ..., 189, 151, 145],\n",
       "         [146, 144, 229, ..., 173, 129, 138],\n",
       "         [135, 120, 237, ..., 150, 111, 122],\n",
       "         [181, 198, 230, ..., 178, 147, 187]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[154, 159, 220, ..., 158, 109, 117],\n",
       "         [144, 129, 235, ..., 149, 108, 120],\n",
       "         [131,  94, 235, ..., 133,  98, 113],\n",
       "         [182, 191, 234, ..., 169, 140, 155]],\n",
       "\n",
       "        [[148, 159, 222, ..., 150, 106,  84],\n",
       "         [138, 128, 233, ..., 142, 101,  82],\n",
       "         [131,  95, 237, ..., 127,  93,  77],\n",
       "         [174, 191, 234, ..., 164, 138, 119]],\n",
       "\n",
       "        [[135, 170, 220, ..., 140, 109,  93],\n",
       "         [125, 141, 229, ..., 142, 104,  91],\n",
       "         [119, 115, 233, ..., 121,  95,  84],\n",
       "         [157, 199, 231, ..., 165, 142, 129]]],\n",
       "\n",
       "\n",
       "       [[[177, 170, 161, ..., 195, 155, 146],\n",
       "         [159, 145, 159, ..., 182, 131, 148],\n",
       "         [150, 115, 155, ..., 157, 113, 133],\n",
       "         [193, 200, 181, ..., 180, 147, 196]],\n",
       "\n",
       "        [[163, 164, 225, ..., 197, 138, 147],\n",
       "         [144, 136, 233, ..., 180, 110, 142],\n",
       "         [133, 108, 237, ..., 156,  88, 127],\n",
       "         [182, 195, 233, ..., 179, 133, 192]],\n",
       "\n",
       "        [[163, 174, 216, ..., 190, 142, 174],\n",
       "         [144, 151, 224, ..., 175, 120, 172],\n",
       "         [131, 127, 227, ..., 152, 100, 158],\n",
       "         [181, 202, 228, ..., 178, 140, 226]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[145, 170, 222, ..., 163, 108, 101],\n",
       "         [138, 141, 231, ..., 152, 103, 102],\n",
       "         [133, 112, 233, ..., 135,  95,  94],\n",
       "         [180, 198, 231, ..., 168, 136, 132]],\n",
       "\n",
       "        [[128, 170, 225, ..., 153, 109,  99],\n",
       "         [121, 144, 233, ..., 150, 103,  98],\n",
       "         [109, 116, 237, ..., 130,  95,  93],\n",
       "         [161, 200, 232, ..., 165, 138, 127]],\n",
       "\n",
       "        [[140, 162, 225, ..., 147, 110, 106],\n",
       "         [133, 134, 231, ..., 146, 104, 104],\n",
       "         [128, 105, 235, ..., 126,  95,  97],\n",
       "         [165, 192, 231, ..., 163, 140, 134]]],\n",
       "\n",
       "\n",
       "       [[[158, 170, 217, ..., 202, 150, 120],\n",
       "         [138, 140, 227, ..., 188, 128, 117],\n",
       "         [120, 117, 229, ..., 151, 100,  99],\n",
       "         [172, 201, 230, ..., 177, 145, 163]],\n",
       "\n",
       "        [[175, 171, 220, ..., 196, 143, 105],\n",
       "         [162, 145, 224, ..., 183, 127,  97],\n",
       "         [148, 122, 227, ..., 153,  97,  76],\n",
       "         [195, 202, 226, ..., 176, 145, 148]],\n",
       "\n",
       "        [[168, 170, 219, ..., 187, 138, 173],\n",
       "         [152, 144, 225, ..., 173, 119, 170],\n",
       "         [140, 118, 229, ..., 148,  93, 154],\n",
       "         [186, 200, 228, ..., 179, 135, 221]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[124, 169, 220, ..., 162, 116, 115],\n",
       "         [120, 141, 231, ..., 153, 105, 116],\n",
       "         [106, 108, 235, ..., 131,  99, 108],\n",
       "         [169, 196, 232, ..., 167, 136, 145]],\n",
       "\n",
       "        [[129, 164, 225, ..., 155, 112,  82],\n",
       "         [127, 140, 225, ..., 150, 104,  83],\n",
       "         [115, 111, 227, ..., 130,  96,  69],\n",
       "         [173, 195, 230, ..., 165, 137, 113]],\n",
       "\n",
       "        [[137, 174, 194, ..., 150, 112, 131],\n",
       "         [131, 152, 183, ..., 145, 105, 136],\n",
       "         [131, 127, 186, ..., 131,  96, 126],\n",
       "         [172, 202, 206, ..., 163, 138, 165]]]], dtype=uint8)"
      ]
     },
     "execution_count": 462,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annots['test_x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 1, ..., 0, 1, 0],\n",
       "       [0, 0, 0, ..., 1, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 1]], dtype=uint8)"
      ]
     },
     "execution_count": 463,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annots['train_y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 400000)"
      ]
     },
     "execution_count": 464,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annots['train_y'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "annots['train_y'][i][j]\n",
    "\n",
    "i : feature('barren land','trees','grassland','none'\n",
    "\n",
    "j : the jth image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[104, 175, 113, ..., 121, 113, 106],\n",
       "         [103, 149, 114, ..., 115, 115,  96],\n",
       "         [ 94, 130, 105, ...,  94,  98,  86],\n",
       "         [133, 146, 163, ..., 160, 168, 150]],\n",
       "\n",
       "        [[114, 169, 126, ..., 123, 116, 115],\n",
       "         [115, 148, 131, ..., 116, 122, 111],\n",
       "         [106, 130, 125, ...,  93, 105, 100],\n",
       "         [145, 141, 176, ..., 165, 189, 150]],\n",
       "\n",
       "        [[104, 166, 119, ..., 125, 112, 120],\n",
       "         [110, 139, 125, ..., 120, 120, 112],\n",
       "         [104, 125, 119, ...,  96,  94, 106],\n",
       "         [138, 133, 168, ..., 169, 194, 144]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 99, 185,  68, ..., 116, 113, 105],\n",
       "         [ 99, 160,  74, ..., 121, 113,  95],\n",
       "         [ 81, 138,  82, ...,  97,  97,  84],\n",
       "         [157, 125,  93, ..., 187, 190, 128]],\n",
       "\n",
       "        [[126, 157,  69, ..., 113, 111, 109],\n",
       "         [134, 142,  67, ..., 118, 113, 101],\n",
       "         [124, 122,  61, ...,  93,  94,  97],\n",
       "         [180, 117,  97, ..., 183, 185, 143]],\n",
       "\n",
       "        [[105, 161,  82, ..., 120, 107, 102],\n",
       "         [115, 140,  85, ..., 126, 111,  95],\n",
       "         [112, 130,  80, ..., 106,  95,  95],\n",
       "         [153, 124, 127, ..., 190, 184, 141]]],\n",
       "\n",
       "\n",
       "       [[[104, 173,  96, ..., 126, 137, 117],\n",
       "         [104, 152,  95, ..., 116, 140, 110],\n",
       "         [ 93, 135,  80, ...,  98, 121, 108],\n",
       "         [139, 147, 143, ..., 161, 189, 148]],\n",
       "\n",
       "        [[107, 171,  78, ..., 127, 134, 121],\n",
       "         [113, 140,  68, ..., 121, 144, 116],\n",
       "         [101, 126,  44, ..., 101, 135, 112],\n",
       "         [147, 143, 117, ..., 166, 197, 154]],\n",
       "\n",
       "        [[ 89, 168, 105, ..., 125, 105, 116],\n",
       "         [ 98, 139, 103, ..., 121, 107, 114],\n",
       "         [ 87, 123,  95, ...,  94,  87, 108],\n",
       "         [127, 137, 140, ..., 164, 169, 146]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[156, 189,  51, ..., 126, 115, 111],\n",
       "         [169, 165,  38, ..., 135, 124, 104],\n",
       "         [162, 132,  29, ..., 119, 117,  92],\n",
       "         [203, 127,  75, ..., 198, 193, 141]],\n",
       "\n",
       "        [[114, 170,  97, ..., 120, 109, 106],\n",
       "         [114, 147,  97, ..., 126, 108, 100],\n",
       "         [104, 132,  99, ..., 106, 105,  95],\n",
       "         [170, 125, 132, ..., 190, 178, 143]],\n",
       "\n",
       "        [[102, 168,  97, ..., 118, 111, 110],\n",
       "         [105, 146, 102, ..., 124, 123,  98],\n",
       "         [ 97, 134,  99, ..., 102, 119, 104],\n",
       "         [152, 131, 145, ..., 187, 186, 137]]],\n",
       "\n",
       "\n",
       "       [[[ 95, 168,  94, ..., 129, 123, 118],\n",
       "         [ 94, 145,  95, ..., 121, 125, 108],\n",
       "         [ 89, 125,  82, ..., 101, 108, 118],\n",
       "         [133, 139, 139, ..., 162, 177, 148]],\n",
       "\n",
       "        [[100, 170,  94, ..., 127, 137, 111],\n",
       "         [101, 140,  90, ..., 122, 147, 107],\n",
       "         [ 93, 126,  76, ..., 101, 143, 110],\n",
       "         [159, 141, 131, ..., 167, 199, 145]],\n",
       "\n",
       "        [[ 99, 173, 112, ..., 124, 113, 105],\n",
       "         [108, 141, 110, ..., 120, 115, 105],\n",
       "         [ 99, 127, 108, ...,  94, 103,  94],\n",
       "         [145, 139, 146, ..., 163, 174, 151]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[189, 184,  59, ..., 113, 108, 116],\n",
       "         [212, 158,  56, ..., 118, 115, 106],\n",
       "         [210, 135,  45, ...,  93, 115, 107],\n",
       "         [231, 129,  96, ..., 180, 178, 143]],\n",
       "\n",
       "        [[108, 171,  85, ..., 115,  60, 108],\n",
       "         [100, 145,  93, ..., 120,  41, 105],\n",
       "         [ 92, 136,  87, ...,  97,  22, 100],\n",
       "         [153, 127, 134, ..., 182, 122, 151]],\n",
       "\n",
       "        [[104, 176, 105, ..., 115,  80,  91],\n",
       "         [107, 156, 119, ..., 121,  86,  87],\n",
       "         [ 99, 128, 117, ...,  99,  77,  83],\n",
       "         [150, 129, 166, ..., 184, 146, 131]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[ 95,  90, 114, ..., 188, 118,  84],\n",
       "         [106, 103, 120, ..., 178, 123,  96],\n",
       "         [104, 112, 115, ..., 176, 121,  77],\n",
       "         [121, 148, 174, ..., 168, 181, 126]],\n",
       "\n",
       "        [[ 86,  80, 120, ..., 194,  93,  95],\n",
       "         [ 95,  97, 131, ..., 189, 101, 106],\n",
       "         [ 98, 104, 125, ..., 188,  89,  88],\n",
       "         [120, 139, 178, ..., 176, 171, 142]],\n",
       "\n",
       "        [[103,  80, 103, ..., 185, 105, 103],\n",
       "         [111,  97, 115, ..., 183, 120, 101],\n",
       "         [116, 105, 106, ..., 186, 104,  91],\n",
       "         [134, 137, 163, ..., 178, 192, 150]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[149, 177,  84, ..., 117,  92, 111],\n",
       "         [152, 155,  85, ..., 114, 105, 100],\n",
       "         [150, 133,  57, ...,  93,  93,  97],\n",
       "         [193, 140, 139, ..., 157, 178, 131]],\n",
       "\n",
       "        [[102, 175, 113, ..., 119,  70, 104],\n",
       "         [ 86, 151, 114, ..., 117,  71, 100],\n",
       "         [ 76, 128, 103, ...,  95,  43,  92],\n",
       "         [143, 140, 166, ..., 162, 153, 143]],\n",
       "\n",
       "        [[110, 161, 115, ..., 115, 114,  99],\n",
       "         [ 99, 138, 121, ..., 115, 137,  87],\n",
       "         [ 92, 127, 108, ...,  93, 137,  88],\n",
       "         [147, 141, 175, ..., 158, 202, 133]]],\n",
       "\n",
       "\n",
       "       [[[ 90, 123,  88, ..., 177,  79, 109],\n",
       "         [100, 127,  91, ..., 167,  65, 108],\n",
       "         [ 99, 110,  77, ..., 160,  34,  97],\n",
       "         [114, 164, 141, ..., 151, 145, 157]],\n",
       "\n",
       "        [[ 90,  97,  82, ..., 176,  93, 111],\n",
       "         [ 99, 110,  79, ..., 163, 100, 112],\n",
       "         [100, 109,  58, ..., 154,  79, 107],\n",
       "         [119, 155, 129, ..., 147, 171, 169]],\n",
       "\n",
       "        [[ 97,  87,  75, ..., 158,  82, 127],\n",
       "         [102, 101,  69, ..., 142,  90, 132],\n",
       "         [105, 108,  52, ..., 129,  53, 128],\n",
       "         [121, 147, 124, ..., 132, 170, 181]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[124, 145, 102, ..., 130, 106, 111],\n",
       "         [121, 137, 101, ..., 123, 117, 103],\n",
       "         [120, 118,  86, ..., 111, 107,  90],\n",
       "         [188, 141, 150, ..., 162, 186, 137]],\n",
       "\n",
       "        [[108, 138, 120, ..., 123,  96, 108],\n",
       "         [102, 136, 123, ..., 118, 104, 101],\n",
       "         [100, 118, 113, ..., 102, 102,  87],\n",
       "         [160, 140, 171, ..., 161, 181, 138]],\n",
       "\n",
       "        [[107, 139, 126, ..., 120, 117, 115],\n",
       "         [104, 135, 132, ..., 116, 137, 104],\n",
       "         [ 98, 116, 122, ...,  95, 138, 102],\n",
       "         [145, 135, 183, ..., 158, 200, 142]]],\n",
       "\n",
       "\n",
       "       [[[ 90, 155,  87, ..., 152,  88, 106],\n",
       "         [ 99, 151,  88, ..., 138,  82,  91],\n",
       "         [ 98, 122,  82, ..., 126,  48,  81],\n",
       "         [114, 173, 138, ..., 143, 155, 144]],\n",
       "\n",
       "        [[ 92, 125,  72, ..., 155, 113, 149],\n",
       "         [ 98, 125,  67, ..., 141, 124, 160],\n",
       "         [ 98, 116,  52, ..., 130, 106, 158],\n",
       "         [102, 165, 116, ..., 143, 195, 199]],\n",
       "\n",
       "        [[103, 117,  93, ..., 142, 107, 110],\n",
       "         [107, 119,  90, ..., 128, 120, 110],\n",
       "         [105, 110,  91, ..., 113,  93, 103],\n",
       "         [101, 154, 143, ..., 132, 195, 168]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[110, 129, 132, ..., 131,  94, 106],\n",
       "         [104, 122, 131, ..., 122,  96, 102],\n",
       "         [ 95, 119, 129, ..., 106,  82,  72],\n",
       "         [141, 132, 177, ..., 158, 170, 134]],\n",
       "\n",
       "        [[101, 137, 122, ..., 126,  71, 107],\n",
       "         [103, 133, 126, ..., 118,  58, 100],\n",
       "         [ 92, 121, 113, ...,  99,  41,  70],\n",
       "         [138, 134, 172, ..., 155, 150, 135]],\n",
       "\n",
       "        [[103, 134, 130, ..., 126,  62, 111],\n",
       "         [110, 128, 136, ..., 119,  57, 103],\n",
       "         [ 99, 119, 131, ..., 100,  39,  86],\n",
       "         [148, 132, 181, ..., 159, 137, 129]]]], dtype=uint8)"
      ]
     },
     "execution_count": 465,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annots['train_x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28, 4, 400000)"
      ]
     },
     "execution_count": 466,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annots['train_x'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "annots['train_x'][a][b][c][d]\n",
    "\n",
    "a : The first encode the row of the pixel\n",
    "\n",
    "b : the second dimensions encode the column of the pixel\n",
    "\n",
    "c : The third dimension describes the channel: index 0 is red, 1 is green, 2 is blue, and 3 is NIR\n",
    "\n",
    "d : the fourth dimension represents the dth image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0xb7de54190>"
      ]
     },
     "execution_count": 467,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib\n",
    "matplotlib.pyplot.imshow(annots['train_x'][:,:,:3,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pixel value of the first three channels corresponds to the RGB values of the image. The fourth channel consists of the NIR value. These values are between 0-255 for RGB and NIR.\n",
    "If you plot these values using matplotlib imshow() (Takes RGB channels only) method, you'll be able to see the different landscapes present in the dataset.\n",
    "\n",
    "https://piazza.com/class/jzk7smzzlk06lq?cid=159\n",
    "\n",
    "What is channel in image data?\n",
    "\n",
    "refer to:\n",
    "\n",
    "https://en.wikipedia.org/wiki/Channel_(digital_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "red = annots['train_x'][:,:,0,0]\n",
    "green = annots['train_x'][:,:,1,0]\n",
    "blue = annots['train_x'][:,:,2,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.16666666666666666, 0, 104)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "red = red.flatten()\n",
    "green = green.flatten()\n",
    "blue = blue.flatten()\n",
    "\n",
    "HSV = colorsys.rgb_to_hsv(red[0],green[0],blue[0])\n",
    "HSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert RGB to HSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import colorsys\n",
    "\n",
    "\n",
    "def RGB_HSV_converter(data,x):\n",
    "    \"\"\"This function convert all the RBG values into HSV format in an image,\n",
    "    x is the index of the image\"\"\"\n",
    "    \n",
    "    red = annots[data][:,:,0,x]\n",
    "\n",
    "    green = annots[data][:,:,1,x]\n",
    "\n",
    "    blue = annots[data][:,:,2,x]\n",
    "    \n",
    "    NIR = annots[data][:,:,3,x]\n",
    "\n",
    "    red = red.flatten()\n",
    "    green = green.flatten()\n",
    "    blue = blue.flatten()\n",
    "    NIR = NIR.flatten()\n",
    "    \n",
    "    hue = np.ones(784)\n",
    "    saturation = np.ones(784)\n",
    "    value = np.ones(784)\n",
    "\n",
    "    for i in range(784):\n",
    "        HSV = colorsys.rgb_to_hsv(red[i]/float(255),green[i]/float(255),blue[i]/float(255))\n",
    "        hue[i] = HSV[0]\n",
    "        saturation[i] = HSV[1]\n",
    "        value[i] = HSV[2]\n",
    "        \n",
    "    hue_mean = np.mean(hue)\n",
    "    hue_std = np.std(hue)\n",
    "\n",
    "    saturation_mean = np.mean(saturation)\n",
    "    saturation_std = np.std(saturation)\n",
    "\n",
    "    value_mean = np.mean(value)\n",
    "    value_std = np.std(value)\n",
    "    \n",
    "    NIR_mean = np.mean(NIR)\n",
    "    NIR_std = np.std(NIR)\n",
    "    \n",
    "    return [hue_mean, hue_std, saturation_mean, saturation_std, value_mean, value_std, NIR_mean, NIR_std]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restruct the array\n",
    "\n",
    "refer to:\n",
    "    \n",
    "https://blog.csdn.net/Haiyang_Duan/article/details/79224835"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.30235195610327736,\n",
       " 0.2212819474514795,\n",
       " 0.09961030867850981,\n",
       " 0.06551973806620635,\n",
       " 0.44360744297719096,\n",
       " 0.08357868567820557,\n",
       " 147.09311224489795,\n",
       " 26.336378842164564]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RGB_HSV_converter('train_x',0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hue_mean</th>\n",
       "      <th>hue_std</th>\n",
       "      <th>saturation_mean</th>\n",
       "      <th>saturation_std</th>\n",
       "      <th>value_mean</th>\n",
       "      <th>value_std</th>\n",
       "      <th>NIR_mean</th>\n",
       "      <th>NIR_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.302352</td>\n",
       "      <td>0.221282</td>\n",
       "      <td>0.099610</td>\n",
       "      <td>0.065520</td>\n",
       "      <td>0.443607</td>\n",
       "      <td>0.083579</td>\n",
       "      <td>147.093112</td>\n",
       "      <td>26.336379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.094648</td>\n",
       "      <td>0.111863</td>\n",
       "      <td>0.233111</td>\n",
       "      <td>0.046380</td>\n",
       "      <td>0.651581</td>\n",
       "      <td>0.067891</td>\n",
       "      <td>145.095663</td>\n",
       "      <td>12.551213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.363837</td>\n",
       "      <td>0.231357</td>\n",
       "      <td>0.184358</td>\n",
       "      <td>0.144247</td>\n",
       "      <td>0.351676</td>\n",
       "      <td>0.108887</td>\n",
       "      <td>121.929847</td>\n",
       "      <td>41.970032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.183581</td>\n",
       "      <td>0.226149</td>\n",
       "      <td>0.074254</td>\n",
       "      <td>0.066595</td>\n",
       "      <td>0.433193</td>\n",
       "      <td>0.118928</td>\n",
       "      <td>127.181122</td>\n",
       "      <td>37.392367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.133382</td>\n",
       "      <td>0.113695</td>\n",
       "      <td>0.134510</td>\n",
       "      <td>0.056476</td>\n",
       "      <td>0.422039</td>\n",
       "      <td>0.054106</td>\n",
       "      <td>135.001276</td>\n",
       "      <td>8.643964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.094021</td>\n",
       "      <td>0.010007</td>\n",
       "      <td>0.300761</td>\n",
       "      <td>0.036946</td>\n",
       "      <td>0.601586</td>\n",
       "      <td>0.031434</td>\n",
       "      <td>188.901786</td>\n",
       "      <td>6.141968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.505201</td>\n",
       "      <td>0.298407</td>\n",
       "      <td>0.256446</td>\n",
       "      <td>0.131016</td>\n",
       "      <td>0.518362</td>\n",
       "      <td>0.094913</td>\n",
       "      <td>137.707908</td>\n",
       "      <td>33.141589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.339751</td>\n",
       "      <td>0.205087</td>\n",
       "      <td>0.185481</td>\n",
       "      <td>0.128080</td>\n",
       "      <td>0.371028</td>\n",
       "      <td>0.106693</td>\n",
       "      <td>144.323980</td>\n",
       "      <td>37.117534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.120816</td>\n",
       "      <td>0.009858</td>\n",
       "      <td>0.228213</td>\n",
       "      <td>0.017643</td>\n",
       "      <td>0.767197</td>\n",
       "      <td>0.049470</td>\n",
       "      <td>186.831633</td>\n",
       "      <td>4.783285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.323907</td>\n",
       "      <td>0.122859</td>\n",
       "      <td>0.073776</td>\n",
       "      <td>0.036104</td>\n",
       "      <td>0.369423</td>\n",
       "      <td>0.037770</td>\n",
       "      <td>70.501276</td>\n",
       "      <td>13.110111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.118077</td>\n",
       "      <td>0.036652</td>\n",
       "      <td>0.210009</td>\n",
       "      <td>0.019520</td>\n",
       "      <td>0.698119</td>\n",
       "      <td>0.029933</td>\n",
       "      <td>178.880102</td>\n",
       "      <td>9.298393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.224678</td>\n",
       "      <td>0.196030</td>\n",
       "      <td>0.202633</td>\n",
       "      <td>0.172358</td>\n",
       "      <td>0.435394</td>\n",
       "      <td>0.119932</td>\n",
       "      <td>156.955357</td>\n",
       "      <td>35.037725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.294883</td>\n",
       "      <td>0.105841</td>\n",
       "      <td>0.108389</td>\n",
       "      <td>0.051566</td>\n",
       "      <td>0.334034</td>\n",
       "      <td>0.043945</td>\n",
       "      <td>152.647959</td>\n",
       "      <td>14.717009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.065260</td>\n",
       "      <td>0.008642</td>\n",
       "      <td>0.249196</td>\n",
       "      <td>0.054411</td>\n",
       "      <td>0.678641</td>\n",
       "      <td>0.070246</td>\n",
       "      <td>195.911990</td>\n",
       "      <td>11.206488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.257598</td>\n",
       "      <td>0.162957</td>\n",
       "      <td>0.114707</td>\n",
       "      <td>0.062481</td>\n",
       "      <td>0.440471</td>\n",
       "      <td>0.077204</td>\n",
       "      <td>148.497449</td>\n",
       "      <td>25.369514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.259165</td>\n",
       "      <td>0.096152</td>\n",
       "      <td>0.079279</td>\n",
       "      <td>0.032699</td>\n",
       "      <td>0.377431</td>\n",
       "      <td>0.031509</td>\n",
       "      <td>60.764031</td>\n",
       "      <td>10.076578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.199903</td>\n",
       "      <td>0.192104</td>\n",
       "      <td>0.158423</td>\n",
       "      <td>0.089850</td>\n",
       "      <td>0.433403</td>\n",
       "      <td>0.103116</td>\n",
       "      <td>161.065051</td>\n",
       "      <td>37.949814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.143097</td>\n",
       "      <td>0.026116</td>\n",
       "      <td>0.154879</td>\n",
       "      <td>0.032605</td>\n",
       "      <td>0.540811</td>\n",
       "      <td>0.028667</td>\n",
       "      <td>182.318878</td>\n",
       "      <td>6.088870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.418035</td>\n",
       "      <td>0.076926</td>\n",
       "      <td>0.024245</td>\n",
       "      <td>0.014628</td>\n",
       "      <td>0.880182</td>\n",
       "      <td>0.017647</td>\n",
       "      <td>132.897959</td>\n",
       "      <td>12.241190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.090547</td>\n",
       "      <td>0.012531</td>\n",
       "      <td>0.260698</td>\n",
       "      <td>0.073245</td>\n",
       "      <td>0.604662</td>\n",
       "      <td>0.079041</td>\n",
       "      <td>192.567602</td>\n",
       "      <td>11.619522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.410024</td>\n",
       "      <td>0.270165</td>\n",
       "      <td>0.255100</td>\n",
       "      <td>0.139961</td>\n",
       "      <td>0.487465</td>\n",
       "      <td>0.091970</td>\n",
       "      <td>166.469388</td>\n",
       "      <td>29.715429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.096251</td>\n",
       "      <td>0.016713</td>\n",
       "      <td>0.190064</td>\n",
       "      <td>0.017888</td>\n",
       "      <td>0.771699</td>\n",
       "      <td>0.035309</td>\n",
       "      <td>186.410714</td>\n",
       "      <td>6.827293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.287357</td>\n",
       "      <td>0.049041</td>\n",
       "      <td>0.136739</td>\n",
       "      <td>0.032784</td>\n",
       "      <td>0.381288</td>\n",
       "      <td>0.031395</td>\n",
       "      <td>176.081633</td>\n",
       "      <td>3.566206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.098278</td>\n",
       "      <td>0.015287</td>\n",
       "      <td>0.190112</td>\n",
       "      <td>0.017057</td>\n",
       "      <td>0.710459</td>\n",
       "      <td>0.037150</td>\n",
       "      <td>178.320153</td>\n",
       "      <td>6.701226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.054682</td>\n",
       "      <td>0.036111</td>\n",
       "      <td>0.157220</td>\n",
       "      <td>0.023693</td>\n",
       "      <td>0.675190</td>\n",
       "      <td>0.038236</td>\n",
       "      <td>177.823980</td>\n",
       "      <td>5.839227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.142249</td>\n",
       "      <td>0.020309</td>\n",
       "      <td>0.196524</td>\n",
       "      <td>0.022120</td>\n",
       "      <td>0.661980</td>\n",
       "      <td>0.022559</td>\n",
       "      <td>186.443878</td>\n",
       "      <td>4.419277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.124570</td>\n",
       "      <td>0.014952</td>\n",
       "      <td>0.182402</td>\n",
       "      <td>0.027276</td>\n",
       "      <td>0.629192</td>\n",
       "      <td>0.027889</td>\n",
       "      <td>156.719388</td>\n",
       "      <td>3.555727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.228580</td>\n",
       "      <td>0.255039</td>\n",
       "      <td>0.124837</td>\n",
       "      <td>0.070741</td>\n",
       "      <td>0.433738</td>\n",
       "      <td>0.073496</td>\n",
       "      <td>160.730867</td>\n",
       "      <td>22.268601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.417915</td>\n",
       "      <td>0.100338</td>\n",
       "      <td>0.099964</td>\n",
       "      <td>0.035496</td>\n",
       "      <td>0.267582</td>\n",
       "      <td>0.020950</td>\n",
       "      <td>15.969388</td>\n",
       "      <td>9.564714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.058882</td>\n",
       "      <td>0.018570</td>\n",
       "      <td>0.173789</td>\n",
       "      <td>0.025221</td>\n",
       "      <td>0.643407</td>\n",
       "      <td>0.031742</td>\n",
       "      <td>168.224490</td>\n",
       "      <td>8.447655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>0.144382</td>\n",
       "      <td>0.038619</td>\n",
       "      <td>0.147739</td>\n",
       "      <td>0.054936</td>\n",
       "      <td>0.500170</td>\n",
       "      <td>0.093215</td>\n",
       "      <td>166.385204</td>\n",
       "      <td>28.370401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>0.201793</td>\n",
       "      <td>0.092711</td>\n",
       "      <td>0.209780</td>\n",
       "      <td>0.151745</td>\n",
       "      <td>0.463230</td>\n",
       "      <td>0.096313</td>\n",
       "      <td>176.515306</td>\n",
       "      <td>23.943274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>0.371832</td>\n",
       "      <td>0.263645</td>\n",
       "      <td>0.206006</td>\n",
       "      <td>0.186852</td>\n",
       "      <td>0.356888</td>\n",
       "      <td>0.125679</td>\n",
       "      <td>113.873724</td>\n",
       "      <td>46.668617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>0.080508</td>\n",
       "      <td>0.006497</td>\n",
       "      <td>0.322479</td>\n",
       "      <td>0.033790</td>\n",
       "      <td>0.669883</td>\n",
       "      <td>0.029034</td>\n",
       "      <td>196.528061</td>\n",
       "      <td>5.016476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>0.226744</td>\n",
       "      <td>0.191036</td>\n",
       "      <td>0.128048</td>\n",
       "      <td>0.087574</td>\n",
       "      <td>0.487135</td>\n",
       "      <td>0.106592</td>\n",
       "      <td>161.588010</td>\n",
       "      <td>29.920642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>0.107954</td>\n",
       "      <td>0.012343</td>\n",
       "      <td>0.202794</td>\n",
       "      <td>0.019610</td>\n",
       "      <td>0.843432</td>\n",
       "      <td>0.026127</td>\n",
       "      <td>207.057398</td>\n",
       "      <td>5.633856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>0.297821</td>\n",
       "      <td>0.056448</td>\n",
       "      <td>0.226261</td>\n",
       "      <td>0.069716</td>\n",
       "      <td>0.371939</td>\n",
       "      <td>0.071675</td>\n",
       "      <td>161.832908</td>\n",
       "      <td>12.280372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>0.098561</td>\n",
       "      <td>0.015847</td>\n",
       "      <td>0.210137</td>\n",
       "      <td>0.023167</td>\n",
       "      <td>0.744113</td>\n",
       "      <td>0.046570</td>\n",
       "      <td>181.278061</td>\n",
       "      <td>5.239833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>0.160981</td>\n",
       "      <td>0.192551</td>\n",
       "      <td>0.137450</td>\n",
       "      <td>0.109348</td>\n",
       "      <td>0.503551</td>\n",
       "      <td>0.139881</td>\n",
       "      <td>144.524235</td>\n",
       "      <td>24.749035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>0.422120</td>\n",
       "      <td>0.278068</td>\n",
       "      <td>0.242267</td>\n",
       "      <td>0.174727</td>\n",
       "      <td>0.330557</td>\n",
       "      <td>0.120522</td>\n",
       "      <td>101.417092</td>\n",
       "      <td>49.470031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>0.432954</td>\n",
       "      <td>0.337695</td>\n",
       "      <td>0.216279</td>\n",
       "      <td>0.126726</td>\n",
       "      <td>0.512175</td>\n",
       "      <td>0.086145</td>\n",
       "      <td>126.614796</td>\n",
       "      <td>33.811634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>0.290693</td>\n",
       "      <td>0.189626</td>\n",
       "      <td>0.173538</td>\n",
       "      <td>0.138263</td>\n",
       "      <td>0.387155</td>\n",
       "      <td>0.101544</td>\n",
       "      <td>147.673469</td>\n",
       "      <td>35.297721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>0.223808</td>\n",
       "      <td>0.181689</td>\n",
       "      <td>0.120116</td>\n",
       "      <td>0.075077</td>\n",
       "      <td>0.429012</td>\n",
       "      <td>0.096905</td>\n",
       "      <td>150.698980</td>\n",
       "      <td>35.605458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>0.088761</td>\n",
       "      <td>0.080352</td>\n",
       "      <td>0.162985</td>\n",
       "      <td>0.057509</td>\n",
       "      <td>0.485429</td>\n",
       "      <td>0.081687</td>\n",
       "      <td>139.471939</td>\n",
       "      <td>12.691863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>0.220533</td>\n",
       "      <td>0.221353</td>\n",
       "      <td>0.125242</td>\n",
       "      <td>0.087533</td>\n",
       "      <td>0.467142</td>\n",
       "      <td>0.095278</td>\n",
       "      <td>153.042092</td>\n",
       "      <td>28.635411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>0.429677</td>\n",
       "      <td>0.306905</td>\n",
       "      <td>0.183033</td>\n",
       "      <td>0.100551</td>\n",
       "      <td>0.251931</td>\n",
       "      <td>0.074114</td>\n",
       "      <td>75.853316</td>\n",
       "      <td>37.850642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>0.464385</td>\n",
       "      <td>0.314638</td>\n",
       "      <td>0.232274</td>\n",
       "      <td>0.123270</td>\n",
       "      <td>0.523985</td>\n",
       "      <td>0.090114</td>\n",
       "      <td>132.357143</td>\n",
       "      <td>34.580172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>0.307482</td>\n",
       "      <td>0.256538</td>\n",
       "      <td>0.094528</td>\n",
       "      <td>0.063967</td>\n",
       "      <td>0.454812</td>\n",
       "      <td>0.074864</td>\n",
       "      <td>147.665816</td>\n",
       "      <td>24.586386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>0.064766</td>\n",
       "      <td>0.012833</td>\n",
       "      <td>0.233541</td>\n",
       "      <td>0.063140</td>\n",
       "      <td>0.684899</td>\n",
       "      <td>0.082885</td>\n",
       "      <td>200.404337</td>\n",
       "      <td>12.634119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>0.228917</td>\n",
       "      <td>0.095383</td>\n",
       "      <td>0.130986</td>\n",
       "      <td>0.061288</td>\n",
       "      <td>0.309779</td>\n",
       "      <td>0.035799</td>\n",
       "      <td>146.908163</td>\n",
       "      <td>13.004188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>0.334456</td>\n",
       "      <td>0.131544</td>\n",
       "      <td>0.184961</td>\n",
       "      <td>0.082587</td>\n",
       "      <td>0.284384</td>\n",
       "      <td>0.049974</td>\n",
       "      <td>148.169643</td>\n",
       "      <td>10.553099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>0.100061</td>\n",
       "      <td>0.011031</td>\n",
       "      <td>0.227174</td>\n",
       "      <td>0.018211</td>\n",
       "      <td>0.778016</td>\n",
       "      <td>0.015105</td>\n",
       "      <td>182.019133</td>\n",
       "      <td>6.772799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>0.229310</td>\n",
       "      <td>0.194027</td>\n",
       "      <td>0.118105</td>\n",
       "      <td>0.075874</td>\n",
       "      <td>0.445623</td>\n",
       "      <td>0.082651</td>\n",
       "      <td>157.378827</td>\n",
       "      <td>21.943704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>0.096530</td>\n",
       "      <td>0.081915</td>\n",
       "      <td>0.186537</td>\n",
       "      <td>0.071273</td>\n",
       "      <td>0.478476</td>\n",
       "      <td>0.092428</td>\n",
       "      <td>143.173469</td>\n",
       "      <td>12.059504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>0.156582</td>\n",
       "      <td>0.227217</td>\n",
       "      <td>0.124846</td>\n",
       "      <td>0.049071</td>\n",
       "      <td>0.515321</td>\n",
       "      <td>0.047581</td>\n",
       "      <td>158.863520</td>\n",
       "      <td>16.095474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>0.072522</td>\n",
       "      <td>0.013298</td>\n",
       "      <td>0.243911</td>\n",
       "      <td>0.018525</td>\n",
       "      <td>0.801751</td>\n",
       "      <td>0.035308</td>\n",
       "      <td>177.931122</td>\n",
       "      <td>10.914573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>0.110978</td>\n",
       "      <td>0.010385</td>\n",
       "      <td>0.239708</td>\n",
       "      <td>0.015911</td>\n",
       "      <td>0.777761</td>\n",
       "      <td>0.036407</td>\n",
       "      <td>191.793367</td>\n",
       "      <td>4.037851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>0.145845</td>\n",
       "      <td>0.016786</td>\n",
       "      <td>0.198009</td>\n",
       "      <td>0.017062</td>\n",
       "      <td>0.697934</td>\n",
       "      <td>0.019915</td>\n",
       "      <td>198.500000</td>\n",
       "      <td>4.123415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>0.135635</td>\n",
       "      <td>0.042561</td>\n",
       "      <td>0.160427</td>\n",
       "      <td>0.031436</td>\n",
       "      <td>0.519403</td>\n",
       "      <td>0.026092</td>\n",
       "      <td>181.576531</td>\n",
       "      <td>6.982797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>0.124789</td>\n",
       "      <td>0.038715</td>\n",
       "      <td>0.193047</td>\n",
       "      <td>0.036818</td>\n",
       "      <td>0.648254</td>\n",
       "      <td>0.067055</td>\n",
       "      <td>164.616071</td>\n",
       "      <td>8.719073</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     hue_mean   hue_std  saturation_mean  saturation_std  value_mean  \\\n",
       "0    0.302352  0.221282         0.099610        0.065520    0.443607   \n",
       "1    0.094648  0.111863         0.233111        0.046380    0.651581   \n",
       "2    0.363837  0.231357         0.184358        0.144247    0.351676   \n",
       "3    0.183581  0.226149         0.074254        0.066595    0.433193   \n",
       "4    0.133382  0.113695         0.134510        0.056476    0.422039   \n",
       "5    0.094021  0.010007         0.300761        0.036946    0.601586   \n",
       "6    0.505201  0.298407         0.256446        0.131016    0.518362   \n",
       "7    0.339751  0.205087         0.185481        0.128080    0.371028   \n",
       "8    0.120816  0.009858         0.228213        0.017643    0.767197   \n",
       "9    0.323907  0.122859         0.073776        0.036104    0.369423   \n",
       "10   0.118077  0.036652         0.210009        0.019520    0.698119   \n",
       "11   0.224678  0.196030         0.202633        0.172358    0.435394   \n",
       "12   0.294883  0.105841         0.108389        0.051566    0.334034   \n",
       "13   0.065260  0.008642         0.249196        0.054411    0.678641   \n",
       "14   0.257598  0.162957         0.114707        0.062481    0.440471   \n",
       "15   0.259165  0.096152         0.079279        0.032699    0.377431   \n",
       "16   0.199903  0.192104         0.158423        0.089850    0.433403   \n",
       "17   0.143097  0.026116         0.154879        0.032605    0.540811   \n",
       "18   0.418035  0.076926         0.024245        0.014628    0.880182   \n",
       "19   0.090547  0.012531         0.260698        0.073245    0.604662   \n",
       "20   0.410024  0.270165         0.255100        0.139961    0.487465   \n",
       "21   0.096251  0.016713         0.190064        0.017888    0.771699   \n",
       "22   0.287357  0.049041         0.136739        0.032784    0.381288   \n",
       "23   0.098278  0.015287         0.190112        0.017057    0.710459   \n",
       "24   0.054682  0.036111         0.157220        0.023693    0.675190   \n",
       "25   0.142249  0.020309         0.196524        0.022120    0.661980   \n",
       "26   0.124570  0.014952         0.182402        0.027276    0.629192   \n",
       "27   0.228580  0.255039         0.124837        0.070741    0.433738   \n",
       "28   0.417915  0.100338         0.099964        0.035496    0.267582   \n",
       "29   0.058882  0.018570         0.173789        0.025221    0.643407   \n",
       "..        ...       ...              ...             ...         ...   \n",
       "370  0.144382  0.038619         0.147739        0.054936    0.500170   \n",
       "371  0.201793  0.092711         0.209780        0.151745    0.463230   \n",
       "372  0.371832  0.263645         0.206006        0.186852    0.356888   \n",
       "373  0.080508  0.006497         0.322479        0.033790    0.669883   \n",
       "374  0.226744  0.191036         0.128048        0.087574    0.487135   \n",
       "375  0.107954  0.012343         0.202794        0.019610    0.843432   \n",
       "376  0.297821  0.056448         0.226261        0.069716    0.371939   \n",
       "377  0.098561  0.015847         0.210137        0.023167    0.744113   \n",
       "378  0.160981  0.192551         0.137450        0.109348    0.503551   \n",
       "379  0.422120  0.278068         0.242267        0.174727    0.330557   \n",
       "380  0.432954  0.337695         0.216279        0.126726    0.512175   \n",
       "381  0.290693  0.189626         0.173538        0.138263    0.387155   \n",
       "382  0.223808  0.181689         0.120116        0.075077    0.429012   \n",
       "383  0.088761  0.080352         0.162985        0.057509    0.485429   \n",
       "384  0.220533  0.221353         0.125242        0.087533    0.467142   \n",
       "385  0.429677  0.306905         0.183033        0.100551    0.251931   \n",
       "386  0.464385  0.314638         0.232274        0.123270    0.523985   \n",
       "387  0.307482  0.256538         0.094528        0.063967    0.454812   \n",
       "388  0.064766  0.012833         0.233541        0.063140    0.684899   \n",
       "389  0.228917  0.095383         0.130986        0.061288    0.309779   \n",
       "390  0.334456  0.131544         0.184961        0.082587    0.284384   \n",
       "391  0.100061  0.011031         0.227174        0.018211    0.778016   \n",
       "392  0.229310  0.194027         0.118105        0.075874    0.445623   \n",
       "393  0.096530  0.081915         0.186537        0.071273    0.478476   \n",
       "394  0.156582  0.227217         0.124846        0.049071    0.515321   \n",
       "395  0.072522  0.013298         0.243911        0.018525    0.801751   \n",
       "396  0.110978  0.010385         0.239708        0.015911    0.777761   \n",
       "397  0.145845  0.016786         0.198009        0.017062    0.697934   \n",
       "398  0.135635  0.042561         0.160427        0.031436    0.519403   \n",
       "399  0.124789  0.038715         0.193047        0.036818    0.648254   \n",
       "\n",
       "     value_std    NIR_mean    NIR_std  \n",
       "0     0.083579  147.093112  26.336379  \n",
       "1     0.067891  145.095663  12.551213  \n",
       "2     0.108887  121.929847  41.970032  \n",
       "3     0.118928  127.181122  37.392367  \n",
       "4     0.054106  135.001276   8.643964  \n",
       "5     0.031434  188.901786   6.141968  \n",
       "6     0.094913  137.707908  33.141589  \n",
       "7     0.106693  144.323980  37.117534  \n",
       "8     0.049470  186.831633   4.783285  \n",
       "9     0.037770   70.501276  13.110111  \n",
       "10    0.029933  178.880102   9.298393  \n",
       "11    0.119932  156.955357  35.037725  \n",
       "12    0.043945  152.647959  14.717009  \n",
       "13    0.070246  195.911990  11.206488  \n",
       "14    0.077204  148.497449  25.369514  \n",
       "15    0.031509   60.764031  10.076578  \n",
       "16    0.103116  161.065051  37.949814  \n",
       "17    0.028667  182.318878   6.088870  \n",
       "18    0.017647  132.897959  12.241190  \n",
       "19    0.079041  192.567602  11.619522  \n",
       "20    0.091970  166.469388  29.715429  \n",
       "21    0.035309  186.410714   6.827293  \n",
       "22    0.031395  176.081633   3.566206  \n",
       "23    0.037150  178.320153   6.701226  \n",
       "24    0.038236  177.823980   5.839227  \n",
       "25    0.022559  186.443878   4.419277  \n",
       "26    0.027889  156.719388   3.555727  \n",
       "27    0.073496  160.730867  22.268601  \n",
       "28    0.020950   15.969388   9.564714  \n",
       "29    0.031742  168.224490   8.447655  \n",
       "..         ...         ...        ...  \n",
       "370   0.093215  166.385204  28.370401  \n",
       "371   0.096313  176.515306  23.943274  \n",
       "372   0.125679  113.873724  46.668617  \n",
       "373   0.029034  196.528061   5.016476  \n",
       "374   0.106592  161.588010  29.920642  \n",
       "375   0.026127  207.057398   5.633856  \n",
       "376   0.071675  161.832908  12.280372  \n",
       "377   0.046570  181.278061   5.239833  \n",
       "378   0.139881  144.524235  24.749035  \n",
       "379   0.120522  101.417092  49.470031  \n",
       "380   0.086145  126.614796  33.811634  \n",
       "381   0.101544  147.673469  35.297721  \n",
       "382   0.096905  150.698980  35.605458  \n",
       "383   0.081687  139.471939  12.691863  \n",
       "384   0.095278  153.042092  28.635411  \n",
       "385   0.074114   75.853316  37.850642  \n",
       "386   0.090114  132.357143  34.580172  \n",
       "387   0.074864  147.665816  24.586386  \n",
       "388   0.082885  200.404337  12.634119  \n",
       "389   0.035799  146.908163  13.004188  \n",
       "390   0.049974  148.169643  10.553099  \n",
       "391   0.015105  182.019133   6.772799  \n",
       "392   0.082651  157.378827  21.943704  \n",
       "393   0.092428  143.173469  12.059504  \n",
       "394   0.047581  158.863520  16.095474  \n",
       "395   0.035308  177.931122  10.914573  \n",
       "396   0.036407  191.793367   4.037851  \n",
       "397   0.019915  198.500000   4.123415  \n",
       "398   0.026092  181.576531   6.982797  \n",
       "399   0.067055  164.616071   8.719073  \n",
       "\n",
       "[400 rows x 8 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# calculate hue_mean, hue_std, saturation_mean, saturation_std, value_mean, value_std of the first 400 images\n",
    "new_feature = []\n",
    "for i in range(400):\n",
    "    new_feature.append(RGB_HSV_converter('train_x',i))\n",
    "# create the pandas DataFrame\n",
    "df_x = pd.DataFrame(new_feature, columns = ['hue_mean', 'hue_std', 'saturation_mean', 'saturation_std', 'value_mean', 'value_std', 'NIR_mean', 'NIR_std'])\n",
    "# print dataframe\n",
    "df_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# normalize the training data\n",
    "#from sklearn import preprocessing\n",
    "# Get column names first\n",
    "#names = df_x.columns\n",
    "# Create the Scaler object\n",
    "#scaler = preprocessing.MinMaxScaler()\n",
    "# Fit your data on the scaler object\n",
    "#scaled_df_x = scaler.fit_transform(df_x)\n",
    "#scaled_df_x = pd.DataFrame(scaled_df_x, columns=names)\n",
    "#scaled_df_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The terms normalization and standardization are sometimes used interchangeably, but they usually refer to different things. Normalization usually means to scale a variable to have a values between 0 and 1, while standardization transforms data to have a mean of zero and a standard deviation of 1.\n",
    "\n",
    "https://scikit-learn.org/stable/modules/preprocessing.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>barren_land</th>\n",
       "      <th>trees</th>\n",
       "      <th>grassland</th>\n",
       "      <th>none</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     barren_land  trees  grassland  none\n",
       "0              0      0          0     1\n",
       "1              1      0          0     0\n",
       "2              0      1          0     0\n",
       "3              0      0          0     1\n",
       "4              0      0          1     0\n",
       "5              1      0          0     0\n",
       "6              0      0          0     1\n",
       "7              0      1          0     0\n",
       "8              1      0          0     0\n",
       "9              0      0          0     1\n",
       "10             1      0          0     0\n",
       "11             0      1          0     0\n",
       "12             0      1          0     0\n",
       "13             1      0          0     0\n",
       "14             0      0          0     1\n",
       "15             0      0          0     1\n",
       "16             0      1          0     0\n",
       "17             0      0          1     0\n",
       "18             0      0          0     1\n",
       "19             1      0          0     0\n",
       "20             0      0          0     1\n",
       "21             1      0          0     0\n",
       "22             0      0          1     0\n",
       "23             1      0          0     0\n",
       "24             1      0          0     0\n",
       "25             1      0          0     0\n",
       "26             1      0          0     0\n",
       "27             0      0          0     1\n",
       "28             0      0          0     1\n",
       "29             1      0          0     0\n",
       "..           ...    ...        ...   ...\n",
       "370            0      0          0     1\n",
       "371            0      1          0     0\n",
       "372            0      1          0     0\n",
       "373            1      0          0     0\n",
       "374            0      0          0     1\n",
       "375            1      0          0     0\n",
       "376            0      1          0     0\n",
       "377            1      0          0     0\n",
       "378            0      0          0     1\n",
       "379            0      1          0     0\n",
       "380            0      0          0     1\n",
       "381            0      1          0     0\n",
       "382            0      1          0     0\n",
       "383            0      0          1     0\n",
       "384            0      0          0     1\n",
       "385            0      1          0     0\n",
       "386            0      0          0     1\n",
       "387            0      0          0     1\n",
       "388            1      0          0     0\n",
       "389            0      1          0     0\n",
       "390            0      1          0     0\n",
       "391            1      0          0     0\n",
       "392            0      0          0     1\n",
       "393            0      0          1     0\n",
       "394            0      0          1     0\n",
       "395            1      0          0     0\n",
       "396            1      0          0     0\n",
       "397            1      0          0     0\n",
       "398            0      0          1     0\n",
       "399            1      0          0     0\n",
       "\n",
       "[400 rows x 4 columns]"
      ]
     },
     "execution_count": 472,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# restruct train_y array by transposition\n",
    "new_feature_y = []\n",
    "for i in range(400):\n",
    "    new_feature_y.append(annots['train_y'][:,i])\n",
    "# create the pandas DataFrame\n",
    "df_y = pd.DataFrame(new_feature_y, columns = ['barren_land', 'trees', 'grassland', 'none'])\n",
    "# print dataframe\n",
    "df_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_y_new = df_y['barren_land']*1+df_y['trees']*2+df_y['grassland']*3+df_y['none']*4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply SVM classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Best Score: ', 0.79)\n",
      "('Best Params: ', {'kernel': 'rbf', 'C': 1000, 'gamma': 0.001})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yutian/anaconda3/envs/py27/lib/python2.7/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['mean_fit_time',\n",
       " 'mean_score_time',\n",
       " 'mean_test_score',\n",
       " 'mean_train_score',\n",
       " 'param_C',\n",
       " 'param_gamma',\n",
       " 'param_kernel',\n",
       " 'params',\n",
       " 'rank_test_score',\n",
       " 'split0_test_score',\n",
       " 'split0_train_score',\n",
       " 'split1_test_score',\n",
       " 'split1_train_score',\n",
       " 'split2_test_score',\n",
       " 'split2_train_score',\n",
       " 'std_fit_time',\n",
       " 'std_score_time',\n",
       " 'std_test_score',\n",
       " 'std_train_score']"
      ]
     },
     "execution_count": 504,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = [\n",
    "  {'C': [0.1, 1, 10, 100, 1000], 'gamma': [0.01, 0.001, 0.0001, 0.00001], 'kernel': ['rbf']},\n",
    " ]\n",
    "svc = svm.SVC()\n",
    "grid = GridSearchCV(estimator= svc,\n",
    "                    param_grid = param_grid,\n",
    "                    scoring = 'accuracy',\n",
    "                    )\n",
    "\n",
    "grid_results = grid.fit(df_x, df_y_new)\n",
    "\n",
    "print('Best Score: ', grid_results.best_score_)\n",
    "print('Best Params: ', grid_results.best_params_)\n",
    "sorted(grid_results.cv_results_.keys())\n",
    "\n",
    "# cv_results_参考： https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Scores with different params: ', [{'kernel': 'rbf', 'C': 0.1, 'gamma': 0.01}, {'kernel': 'rbf', 'C': 0.1, 'gamma': 0.001}, {'kernel': 'rbf', 'C': 0.1, 'gamma': 0.0001}, {'kernel': 'rbf', 'C': 0.1, 'gamma': 1e-05}, {'kernel': 'rbf', 'C': 1, 'gamma': 0.01}, {'kernel': 'rbf', 'C': 1, 'gamma': 0.001}, {'kernel': 'rbf', 'C': 1, 'gamma': 0.0001}, {'kernel': 'rbf', 'C': 1, 'gamma': 1e-05}, {'kernel': 'rbf', 'C': 10, 'gamma': 0.01}, {'kernel': 'rbf', 'C': 10, 'gamma': 0.001}, {'kernel': 'rbf', 'C': 10, 'gamma': 0.0001}, {'kernel': 'rbf', 'C': 10, 'gamma': 1e-05}, {'kernel': 'rbf', 'C': 100, 'gamma': 0.01}, {'kernel': 'rbf', 'C': 100, 'gamma': 0.001}, {'kernel': 'rbf', 'C': 100, 'gamma': 0.0001}, {'kernel': 'rbf', 'C': 100, 'gamma': 1e-05}, {'kernel': 'rbf', 'C': 1000, 'gamma': 0.01}, {'kernel': 'rbf', 'C': 1000, 'gamma': 0.001}, {'kernel': 'rbf', 'C': 1000, 'gamma': 0.0001}, {'kernel': 'rbf', 'C': 1000, 'gamma': 1e-05}])\n"
     ]
    }
   ],
   "source": [
    "print('Scores with different params: ', grid_results.cv_results_['params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Scores with different params: ', array([14, 17, 19, 20,  4, 12, 16, 18,  8,  4, 11, 15,  6,  3, 13,  9,  2,\n",
      "        1,  7,  9], dtype=int32))\n"
     ]
    }
   ],
   "source": [
    "print('Scores with different params: ', grid_results.cv_results_['rank_test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.00557431, 0.0037117 , 0.00389568, 0.0039076 , 0.00407163,\n",
       "        0.00340899, 0.00339834, 0.00384529, 0.00385062, 0.0032661 ,\n",
       "        0.00330806, 0.00352963, 0.00570671, 0.00422192, 0.00383266,\n",
       "        0.0032347 , 0.0162367 , 0.01142899, 0.0072124 , 0.00380929]),\n",
       " 'mean_score_time': array([0.00220402, 0.00168355, 0.00165502, 0.0017364 , 0.00151499,\n",
       "        0.00160003, 0.00161568, 0.0018994 , 0.0014751 , 0.00151436,\n",
       "        0.00168069, 0.0016017 , 0.00150998, 0.00142972, 0.00153971,\n",
       "        0.00160511, 0.00140333, 0.00147263, 0.00142535, 0.00153963]),\n",
       " 'mean_test_score': array([0.6275, 0.58  , 0.55  , 0.3675, 0.715 , 0.6825, 0.6175, 0.5525,\n",
       "        0.705 , 0.715 , 0.685 , 0.625 , 0.7125, 0.7175, 0.68  , 0.6975,\n",
       "        0.7425, 0.79  , 0.71  , 0.6975]),\n",
       " 'mean_train_score': array([0.63754424, 0.58876592, 0.54999859, 0.36750115, 0.80000563,\n",
       "        0.70503506, 0.62126759, 0.5537486 , 0.84127923, 0.74125858,\n",
       "        0.68876311, 0.62376916, 0.89128251, 0.80125407, 0.70750378,\n",
       "        0.71002882, 0.96626397, 0.89004346, 0.74750547, 0.71253039]),\n",
       " 'param_C': masked_array(data=[0.1, 0.1, 0.1, 0.1, 1, 1, 1, 1, 10, 10, 10, 10, 100,\n",
       "                    100, 100, 100, 1000, 1000, 1000, 1000],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_gamma': masked_array(data=[0.01, 0.001, 0.0001, 1e-05, 0.01, 0.001, 0.0001, 1e-05,\n",
       "                    0.01, 0.001, 0.0001, 1e-05, 0.01, 0.001, 0.0001, 1e-05,\n",
       "                    0.01, 0.001, 0.0001, 1e-05],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_kernel': masked_array(data=['rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf',\n",
       "                    'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf',\n",
       "                    'rbf', 'rbf', 'rbf', 'rbf'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'C': 0.1, 'gamma': 0.01, 'kernel': 'rbf'},\n",
       "  {'C': 0.1, 'gamma': 0.001, 'kernel': 'rbf'},\n",
       "  {'C': 0.1, 'gamma': 0.0001, 'kernel': 'rbf'},\n",
       "  {'C': 0.1, 'gamma': 1e-05, 'kernel': 'rbf'},\n",
       "  {'C': 1, 'gamma': 0.01, 'kernel': 'rbf'},\n",
       "  {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'},\n",
       "  {'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'},\n",
       "  {'C': 1, 'gamma': 1e-05, 'kernel': 'rbf'},\n",
       "  {'C': 10, 'gamma': 0.01, 'kernel': 'rbf'},\n",
       "  {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'},\n",
       "  {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'},\n",
       "  {'C': 10, 'gamma': 1e-05, 'kernel': 'rbf'},\n",
       "  {'C': 100, 'gamma': 0.01, 'kernel': 'rbf'},\n",
       "  {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'},\n",
       "  {'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'},\n",
       "  {'C': 100, 'gamma': 1e-05, 'kernel': 'rbf'},\n",
       "  {'C': 1000, 'gamma': 0.01, 'kernel': 'rbf'},\n",
       "  {'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'},\n",
       "  {'C': 1000, 'gamma': 0.0001, 'kernel': 'rbf'},\n",
       "  {'C': 1000, 'gamma': 1e-05, 'kernel': 'rbf'}],\n",
       " 'rank_test_score': array([14, 17, 19, 20,  4, 12, 16, 18,  8,  4, 11, 15,  6,  3, 13,  9,  2,\n",
       "         1,  7,  9], dtype=int32),\n",
       " 'split0_test_score': array([0.60447761, 0.58208955, 0.55970149, 0.36567164, 0.64925373,\n",
       "        0.64179104, 0.6119403 , 0.55970149, 0.62686567, 0.68656716,\n",
       "        0.65671642, 0.61940299, 0.64179104, 0.64925373, 0.64179104,\n",
       "        0.6641791 , 0.67164179, 0.69402985, 0.65671642, 0.6641791 ]),\n",
       " 'split0_train_score': array([0.67293233, 0.60150376, 0.54887218, 0.36842105, 0.80451128,\n",
       "        0.73308271, 0.63533835, 0.55263158, 0.86466165, 0.7481203 ,\n",
       "        0.69924812, 0.63909774, 0.91729323, 0.80451128, 0.71052632,\n",
       "        0.73308271, 0.97744361, 0.92481203, 0.7518797 , 0.73684211]),\n",
       " 'split1_test_score': array([0.61654135, 0.56390977, 0.54135338, 0.36842105, 0.73684211,\n",
       "        0.67669173, 0.59398496, 0.54887218, 0.72180451, 0.70676692,\n",
       "        0.67669173, 0.59398496, 0.71428571, 0.71428571, 0.68421053,\n",
       "        0.70676692, 0.72932331, 0.78195489, 0.71428571, 0.70676692]),\n",
       " 'split1_train_score': array([0.62921348, 0.58801498, 0.56179775, 0.3670412 , 0.81273408,\n",
       "        0.70786517, 0.61423221, 0.56928839, 0.83895131, 0.75655431,\n",
       "        0.68913858, 0.62172285, 0.90262172, 0.82022472, 0.71910112,\n",
       "        0.70037453, 0.97752809, 0.89513109, 0.75655431, 0.71535581]),\n",
       " 'split2_test_score': array([0.66165414, 0.59398496, 0.54887218, 0.36842105, 0.7593985 ,\n",
       "        0.72932331, 0.64661654, 0.54887218, 0.76691729, 0.7518797 ,\n",
       "        0.72180451, 0.66165414, 0.78195489, 0.78947368, 0.71428571,\n",
       "        0.72180451, 0.82706767, 0.89473684, 0.7593985 , 0.72180451]),\n",
       " 'split2_train_score': array([0.61048689, 0.57677903, 0.53932584, 0.3670412 , 0.78277154,\n",
       "        0.6741573 , 0.61423221, 0.53932584, 0.82022472, 0.71910112,\n",
       "        0.67790262, 0.61048689, 0.85393258, 0.77902622, 0.6928839 ,\n",
       "        0.69662921, 0.94382022, 0.85018727, 0.7340824 , 0.68539326]),\n",
       " 'std_fit_time': array([7.53106397e-04, 5.97180242e-05, 2.60202930e-05, 3.94942533e-05,\n",
       "        6.46154006e-04, 1.63222125e-04, 4.34996133e-05, 3.23771689e-05,\n",
       "        1.77276180e-04, 1.46501572e-04, 1.51499703e-04, 3.84957213e-05,\n",
       "        5.14341115e-04, 1.95939558e-04, 1.79597867e-04, 2.45137382e-05,\n",
       "        5.66476868e-03, 8.36706383e-04, 5.49475984e-04, 2.14988378e-04]),\n",
       " 'std_score_time': array([5.12142692e-04, 6.70614387e-05, 1.69006468e-05, 1.09502412e-04,\n",
       "        2.47054522e-05, 4.95891540e-05, 2.98047595e-05, 1.87548944e-04,\n",
       "        3.50402318e-05, 6.55896208e-05, 1.03841502e-04, 1.87407721e-05,\n",
       "        9.38623259e-05, 2.06103021e-05, 7.06027689e-05, 6.96308344e-05,\n",
       "        2.25150974e-05, 9.47697774e-05, 7.74850193e-06, 6.40763207e-05]),\n",
       " 'std_test_score': array([0.02460394, 0.01235214, 0.00753736, 0.0012977 , 0.04756178,\n",
       "        0.03599119, 0.02181966, 0.00511133, 0.05842759, 0.02730564,\n",
       "        0.02722744, 0.02787578, 0.05727087, 0.05732483, 0.02976284,\n",
       "        0.02443172, 0.06416903, 0.08218529, 0.0420546 , 0.02443172]),\n",
       " 'std_train_score': array([0.02616498, 0.01010779, 0.00920863, 0.00065047, 0.01264026,\n",
       "        0.02413929, 0.00994953, 0.01225763, 0.01821583, 0.01604156,\n",
       "        0.00871831, 0.01176962, 0.02708107, 0.01697618, 0.01091444,\n",
       "        0.01637311, 0.01587017, 0.0306771 , 0.0096815 , 0.02109871])}"
      ]
     },
     "execution_count": 507,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_results.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>std_train_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>param_kernel</th>\n",
       "      <th>param_C</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>params</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>split1_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.026165</td>\n",
       "      <td>14</td>\n",
       "      <td>0.672932</td>\n",
       "      <td>0.629213</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.610487</td>\n",
       "      <td>0.000512</td>\n",
       "      <td>0.661654</td>\n",
       "      <td>0.002204</td>\n",
       "      <td>0.005574</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.024604</td>\n",
       "      <td>0.637544</td>\n",
       "      <td>0.604478</td>\n",
       "      <td>0.6275</td>\n",
       "      <td>{u'kernel': u'rbf', u'C': 0.1, u'gamma': 0.01}</td>\n",
       "      <td>0.000753</td>\n",
       "      <td>0.616541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.010108</td>\n",
       "      <td>17</td>\n",
       "      <td>0.601504</td>\n",
       "      <td>0.588015</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.576779</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.593985</td>\n",
       "      <td>0.001684</td>\n",
       "      <td>0.003712</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.012352</td>\n",
       "      <td>0.588766</td>\n",
       "      <td>0.582090</td>\n",
       "      <td>0.5800</td>\n",
       "      <td>{u'kernel': u'rbf', u'C': 0.1, u'gamma': 0.001}</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.563910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.009209</td>\n",
       "      <td>19</td>\n",
       "      <td>0.548872</td>\n",
       "      <td>0.561798</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.539326</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.548872</td>\n",
       "      <td>0.001655</td>\n",
       "      <td>0.003896</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.007537</td>\n",
       "      <td>0.549999</td>\n",
       "      <td>0.559701</td>\n",
       "      <td>0.5500</td>\n",
       "      <td>{u'kernel': u'rbf', u'C': 0.1, u'gamma': 0.0001}</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.541353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000650</td>\n",
       "      <td>20</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.367041</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>0.367041</td>\n",
       "      <td>0.000110</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.001736</td>\n",
       "      <td>0.003908</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.001298</td>\n",
       "      <td>0.367501</td>\n",
       "      <td>0.365672</td>\n",
       "      <td>0.3675</td>\n",
       "      <td>{u'kernel': u'rbf', u'C': 0.1, u'gamma': 1e-05}</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.368421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.012640</td>\n",
       "      <td>4</td>\n",
       "      <td>0.804511</td>\n",
       "      <td>0.812734</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.782772</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.759398</td>\n",
       "      <td>0.001515</td>\n",
       "      <td>0.004072</td>\n",
       "      <td>rbf</td>\n",
       "      <td>1</td>\n",
       "      <td>0.047562</td>\n",
       "      <td>0.800006</td>\n",
       "      <td>0.649254</td>\n",
       "      <td>0.7150</td>\n",
       "      <td>{u'kernel': u'rbf', u'C': 1, u'gamma': 0.01}</td>\n",
       "      <td>0.000646</td>\n",
       "      <td>0.736842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.024139</td>\n",
       "      <td>12</td>\n",
       "      <td>0.733083</td>\n",
       "      <td>0.707865</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.674157</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.729323</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>0.003409</td>\n",
       "      <td>rbf</td>\n",
       "      <td>1</td>\n",
       "      <td>0.035991</td>\n",
       "      <td>0.705035</td>\n",
       "      <td>0.641791</td>\n",
       "      <td>0.6825</td>\n",
       "      <td>{u'kernel': u'rbf', u'C': 1, u'gamma': 0.001}</td>\n",
       "      <td>0.000163</td>\n",
       "      <td>0.676692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.009950</td>\n",
       "      <td>16</td>\n",
       "      <td>0.635338</td>\n",
       "      <td>0.614232</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.614232</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.646617</td>\n",
       "      <td>0.001616</td>\n",
       "      <td>0.003398</td>\n",
       "      <td>rbf</td>\n",
       "      <td>1</td>\n",
       "      <td>0.021820</td>\n",
       "      <td>0.621268</td>\n",
       "      <td>0.611940</td>\n",
       "      <td>0.6175</td>\n",
       "      <td>{u'kernel': u'rbf', u'C': 1, u'gamma': 0.0001}</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.593985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.012258</td>\n",
       "      <td>18</td>\n",
       "      <td>0.552632</td>\n",
       "      <td>0.569288</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>0.539326</td>\n",
       "      <td>0.000188</td>\n",
       "      <td>0.548872</td>\n",
       "      <td>0.001899</td>\n",
       "      <td>0.003845</td>\n",
       "      <td>rbf</td>\n",
       "      <td>1</td>\n",
       "      <td>0.005111</td>\n",
       "      <td>0.553749</td>\n",
       "      <td>0.559701</td>\n",
       "      <td>0.5525</td>\n",
       "      <td>{u'kernel': u'rbf', u'C': 1, u'gamma': 1e-05}</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.548872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.018216</td>\n",
       "      <td>8</td>\n",
       "      <td>0.864662</td>\n",
       "      <td>0.838951</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.820225</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.766917</td>\n",
       "      <td>0.001475</td>\n",
       "      <td>0.003851</td>\n",
       "      <td>rbf</td>\n",
       "      <td>10</td>\n",
       "      <td>0.058428</td>\n",
       "      <td>0.841279</td>\n",
       "      <td>0.626866</td>\n",
       "      <td>0.7050</td>\n",
       "      <td>{u'kernel': u'rbf', u'C': 10, u'gamma': 0.01}</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>0.721805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.016042</td>\n",
       "      <td>4</td>\n",
       "      <td>0.748120</td>\n",
       "      <td>0.756554</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.719101</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>0.751880</td>\n",
       "      <td>0.001514</td>\n",
       "      <td>0.003266</td>\n",
       "      <td>rbf</td>\n",
       "      <td>10</td>\n",
       "      <td>0.027306</td>\n",
       "      <td>0.741259</td>\n",
       "      <td>0.686567</td>\n",
       "      <td>0.7150</td>\n",
       "      <td>{u'kernel': u'rbf', u'C': 10, u'gamma': 0.001}</td>\n",
       "      <td>0.000147</td>\n",
       "      <td>0.706767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.008718</td>\n",
       "      <td>11</td>\n",
       "      <td>0.699248</td>\n",
       "      <td>0.689139</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.677903</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>0.721805</td>\n",
       "      <td>0.001681</td>\n",
       "      <td>0.003308</td>\n",
       "      <td>rbf</td>\n",
       "      <td>10</td>\n",
       "      <td>0.027227</td>\n",
       "      <td>0.688763</td>\n",
       "      <td>0.656716</td>\n",
       "      <td>0.6850</td>\n",
       "      <td>{u'kernel': u'rbf', u'C': 10, u'gamma': 0.0001}</td>\n",
       "      <td>0.000151</td>\n",
       "      <td>0.676692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.011770</td>\n",
       "      <td>15</td>\n",
       "      <td>0.639098</td>\n",
       "      <td>0.621723</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>0.610487</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.661654</td>\n",
       "      <td>0.001602</td>\n",
       "      <td>0.003530</td>\n",
       "      <td>rbf</td>\n",
       "      <td>10</td>\n",
       "      <td>0.027876</td>\n",
       "      <td>0.623769</td>\n",
       "      <td>0.619403</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>{u'kernel': u'rbf', u'C': 10, u'gamma': 1e-05}</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.593985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.027081</td>\n",
       "      <td>6</td>\n",
       "      <td>0.917293</td>\n",
       "      <td>0.902622</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.853933</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.781955</td>\n",
       "      <td>0.001510</td>\n",
       "      <td>0.005707</td>\n",
       "      <td>rbf</td>\n",
       "      <td>100</td>\n",
       "      <td>0.057271</td>\n",
       "      <td>0.891283</td>\n",
       "      <td>0.641791</td>\n",
       "      <td>0.7125</td>\n",
       "      <td>{u'kernel': u'rbf', u'C': 100, u'gamma': 0.01}</td>\n",
       "      <td>0.000514</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.016976</td>\n",
       "      <td>3</td>\n",
       "      <td>0.804511</td>\n",
       "      <td>0.820225</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.779026</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.001430</td>\n",
       "      <td>0.004222</td>\n",
       "      <td>rbf</td>\n",
       "      <td>100</td>\n",
       "      <td>0.057325</td>\n",
       "      <td>0.801254</td>\n",
       "      <td>0.649254</td>\n",
       "      <td>0.7175</td>\n",
       "      <td>{u'kernel': u'rbf', u'C': 100, u'gamma': 0.001}</td>\n",
       "      <td>0.000196</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.010914</td>\n",
       "      <td>13</td>\n",
       "      <td>0.710526</td>\n",
       "      <td>0.719101</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.692884</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.001540</td>\n",
       "      <td>0.003833</td>\n",
       "      <td>rbf</td>\n",
       "      <td>100</td>\n",
       "      <td>0.029763</td>\n",
       "      <td>0.707504</td>\n",
       "      <td>0.641791</td>\n",
       "      <td>0.6800</td>\n",
       "      <td>{u'kernel': u'rbf', u'C': 100, u'gamma': 0.0001}</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>0.684211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.016373</td>\n",
       "      <td>9</td>\n",
       "      <td>0.733083</td>\n",
       "      <td>0.700375</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>0.696629</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>0.721805</td>\n",
       "      <td>0.001605</td>\n",
       "      <td>0.003235</td>\n",
       "      <td>rbf</td>\n",
       "      <td>100</td>\n",
       "      <td>0.024432</td>\n",
       "      <td>0.710029</td>\n",
       "      <td>0.664179</td>\n",
       "      <td>0.6975</td>\n",
       "      <td>{u'kernel': u'rbf', u'C': 100, u'gamma': 1e-05}</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.706767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.015870</td>\n",
       "      <td>2</td>\n",
       "      <td>0.977444</td>\n",
       "      <td>0.977528</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.943820</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.827068</td>\n",
       "      <td>0.001403</td>\n",
       "      <td>0.016237</td>\n",
       "      <td>rbf</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.064169</td>\n",
       "      <td>0.966264</td>\n",
       "      <td>0.671642</td>\n",
       "      <td>0.7425</td>\n",
       "      <td>{u'kernel': u'rbf', u'C': 1000, u'gamma': 0.01}</td>\n",
       "      <td>0.005665</td>\n",
       "      <td>0.729323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.030677</td>\n",
       "      <td>1</td>\n",
       "      <td>0.924812</td>\n",
       "      <td>0.895131</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.850187</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.001473</td>\n",
       "      <td>0.011429</td>\n",
       "      <td>rbf</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.082185</td>\n",
       "      <td>0.890043</td>\n",
       "      <td>0.694030</td>\n",
       "      <td>0.7900</td>\n",
       "      <td>{u'kernel': u'rbf', u'C': 1000, u'gamma': 0.001}</td>\n",
       "      <td>0.000837</td>\n",
       "      <td>0.781955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.009681</td>\n",
       "      <td>7</td>\n",
       "      <td>0.751880</td>\n",
       "      <td>0.756554</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.734082</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.759398</td>\n",
       "      <td>0.001425</td>\n",
       "      <td>0.007212</td>\n",
       "      <td>rbf</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.042055</td>\n",
       "      <td>0.747505</td>\n",
       "      <td>0.656716</td>\n",
       "      <td>0.7100</td>\n",
       "      <td>{u'kernel': u'rbf', u'C': 1000, u'gamma': 0.0001}</td>\n",
       "      <td>0.000549</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.021099</td>\n",
       "      <td>9</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.715356</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>0.685393</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>0.721805</td>\n",
       "      <td>0.001540</td>\n",
       "      <td>0.003809</td>\n",
       "      <td>rbf</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.024432</td>\n",
       "      <td>0.712530</td>\n",
       "      <td>0.664179</td>\n",
       "      <td>0.6975</td>\n",
       "      <td>{u'kernel': u'rbf', u'C': 1000, u'gamma': 1e-05}</td>\n",
       "      <td>0.000215</td>\n",
       "      <td>0.706767</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    std_train_score  rank_test_score  split0_train_score  split1_train_score  \\\n",
       "0          0.026165               14            0.672932            0.629213   \n",
       "1          0.010108               17            0.601504            0.588015   \n",
       "2          0.009209               19            0.548872            0.561798   \n",
       "3          0.000650               20            0.368421            0.367041   \n",
       "4          0.012640                4            0.804511            0.812734   \n",
       "5          0.024139               12            0.733083            0.707865   \n",
       "6          0.009950               16            0.635338            0.614232   \n",
       "7          0.012258               18            0.552632            0.569288   \n",
       "8          0.018216                8            0.864662            0.838951   \n",
       "9          0.016042                4            0.748120            0.756554   \n",
       "10         0.008718               11            0.699248            0.689139   \n",
       "11         0.011770               15            0.639098            0.621723   \n",
       "12         0.027081                6            0.917293            0.902622   \n",
       "13         0.016976                3            0.804511            0.820225   \n",
       "14         0.010914               13            0.710526            0.719101   \n",
       "15         0.016373                9            0.733083            0.700375   \n",
       "16         0.015870                2            0.977444            0.977528   \n",
       "17         0.030677                1            0.924812            0.895131   \n",
       "18         0.009681                7            0.751880            0.756554   \n",
       "19         0.021099                9            0.736842            0.715356   \n",
       "\n",
       "   param_gamma  split2_train_score  std_score_time  split2_test_score  \\\n",
       "0         0.01            0.610487        0.000512           0.661654   \n",
       "1        0.001            0.576779        0.000067           0.593985   \n",
       "2       0.0001            0.539326        0.000017           0.548872   \n",
       "3        1e-05            0.367041        0.000110           0.368421   \n",
       "4         0.01            0.782772        0.000025           0.759398   \n",
       "5        0.001            0.674157        0.000050           0.729323   \n",
       "6       0.0001            0.614232        0.000030           0.646617   \n",
       "7        1e-05            0.539326        0.000188           0.548872   \n",
       "8         0.01            0.820225        0.000035           0.766917   \n",
       "9        0.001            0.719101        0.000066           0.751880   \n",
       "10      0.0001            0.677903        0.000104           0.721805   \n",
       "11       1e-05            0.610487        0.000019           0.661654   \n",
       "12        0.01            0.853933        0.000094           0.781955   \n",
       "13       0.001            0.779026        0.000021           0.789474   \n",
       "14      0.0001            0.692884        0.000071           0.714286   \n",
       "15       1e-05            0.696629        0.000070           0.721805   \n",
       "16        0.01            0.943820        0.000023           0.827068   \n",
       "17       0.001            0.850187        0.000095           0.894737   \n",
       "18      0.0001            0.734082        0.000008           0.759398   \n",
       "19       1e-05            0.685393        0.000064           0.721805   \n",
       "\n",
       "    mean_score_time  mean_fit_time param_kernel param_C  std_test_score  \\\n",
       "0          0.002204       0.005574          rbf     0.1        0.024604   \n",
       "1          0.001684       0.003712          rbf     0.1        0.012352   \n",
       "2          0.001655       0.003896          rbf     0.1        0.007537   \n",
       "3          0.001736       0.003908          rbf     0.1        0.001298   \n",
       "4          0.001515       0.004072          rbf       1        0.047562   \n",
       "5          0.001600       0.003409          rbf       1        0.035991   \n",
       "6          0.001616       0.003398          rbf       1        0.021820   \n",
       "7          0.001899       0.003845          rbf       1        0.005111   \n",
       "8          0.001475       0.003851          rbf      10        0.058428   \n",
       "9          0.001514       0.003266          rbf      10        0.027306   \n",
       "10         0.001681       0.003308          rbf      10        0.027227   \n",
       "11         0.001602       0.003530          rbf      10        0.027876   \n",
       "12         0.001510       0.005707          rbf     100        0.057271   \n",
       "13         0.001430       0.004222          rbf     100        0.057325   \n",
       "14         0.001540       0.003833          rbf     100        0.029763   \n",
       "15         0.001605       0.003235          rbf     100        0.024432   \n",
       "16         0.001403       0.016237          rbf    1000        0.064169   \n",
       "17         0.001473       0.011429          rbf    1000        0.082185   \n",
       "18         0.001425       0.007212          rbf    1000        0.042055   \n",
       "19         0.001540       0.003809          rbf    1000        0.024432   \n",
       "\n",
       "    mean_train_score  split0_test_score  mean_test_score  \\\n",
       "0           0.637544           0.604478           0.6275   \n",
       "1           0.588766           0.582090           0.5800   \n",
       "2           0.549999           0.559701           0.5500   \n",
       "3           0.367501           0.365672           0.3675   \n",
       "4           0.800006           0.649254           0.7150   \n",
       "5           0.705035           0.641791           0.6825   \n",
       "6           0.621268           0.611940           0.6175   \n",
       "7           0.553749           0.559701           0.5525   \n",
       "8           0.841279           0.626866           0.7050   \n",
       "9           0.741259           0.686567           0.7150   \n",
       "10          0.688763           0.656716           0.6850   \n",
       "11          0.623769           0.619403           0.6250   \n",
       "12          0.891283           0.641791           0.7125   \n",
       "13          0.801254           0.649254           0.7175   \n",
       "14          0.707504           0.641791           0.6800   \n",
       "15          0.710029           0.664179           0.6975   \n",
       "16          0.966264           0.671642           0.7425   \n",
       "17          0.890043           0.694030           0.7900   \n",
       "18          0.747505           0.656716           0.7100   \n",
       "19          0.712530           0.664179           0.6975   \n",
       "\n",
       "                                               params  std_fit_time  \\\n",
       "0      {u'kernel': u'rbf', u'C': 0.1, u'gamma': 0.01}      0.000753   \n",
       "1     {u'kernel': u'rbf', u'C': 0.1, u'gamma': 0.001}      0.000060   \n",
       "2    {u'kernel': u'rbf', u'C': 0.1, u'gamma': 0.0001}      0.000026   \n",
       "3     {u'kernel': u'rbf', u'C': 0.1, u'gamma': 1e-05}      0.000039   \n",
       "4        {u'kernel': u'rbf', u'C': 1, u'gamma': 0.01}      0.000646   \n",
       "5       {u'kernel': u'rbf', u'C': 1, u'gamma': 0.001}      0.000163   \n",
       "6      {u'kernel': u'rbf', u'C': 1, u'gamma': 0.0001}      0.000043   \n",
       "7       {u'kernel': u'rbf', u'C': 1, u'gamma': 1e-05}      0.000032   \n",
       "8       {u'kernel': u'rbf', u'C': 10, u'gamma': 0.01}      0.000177   \n",
       "9      {u'kernel': u'rbf', u'C': 10, u'gamma': 0.001}      0.000147   \n",
       "10    {u'kernel': u'rbf', u'C': 10, u'gamma': 0.0001}      0.000151   \n",
       "11     {u'kernel': u'rbf', u'C': 10, u'gamma': 1e-05}      0.000038   \n",
       "12     {u'kernel': u'rbf', u'C': 100, u'gamma': 0.01}      0.000514   \n",
       "13    {u'kernel': u'rbf', u'C': 100, u'gamma': 0.001}      0.000196   \n",
       "14   {u'kernel': u'rbf', u'C': 100, u'gamma': 0.0001}      0.000180   \n",
       "15    {u'kernel': u'rbf', u'C': 100, u'gamma': 1e-05}      0.000025   \n",
       "16    {u'kernel': u'rbf', u'C': 1000, u'gamma': 0.01}      0.005665   \n",
       "17   {u'kernel': u'rbf', u'C': 1000, u'gamma': 0.001}      0.000837   \n",
       "18  {u'kernel': u'rbf', u'C': 1000, u'gamma': 0.0001}      0.000549   \n",
       "19   {u'kernel': u'rbf', u'C': 1000, u'gamma': 1e-05}      0.000215   \n",
       "\n",
       "    split1_test_score  \n",
       "0            0.616541  \n",
       "1            0.563910  \n",
       "2            0.541353  \n",
       "3            0.368421  \n",
       "4            0.736842  \n",
       "5            0.676692  \n",
       "6            0.593985  \n",
       "7            0.548872  \n",
       "8            0.721805  \n",
       "9            0.706767  \n",
       "10           0.676692  \n",
       "11           0.593985  \n",
       "12           0.714286  \n",
       "13           0.714286  \n",
       "14           0.684211  \n",
       "15           0.706767  \n",
       "16           0.729323  \n",
       "17           0.781955  \n",
       "18           0.714286  \n",
       "19           0.706767  "
      ]
     },
     "execution_count": 510,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_result_table = pd.DataFrame(grid_results.cv_results_, columns = grid_results.cv_results_.keys())\n",
    "cv_result_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Best Score: ', 0.9275)\n",
      "('Best Params: ', {'kernel': 'linear', 'C': 10})\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}\n",
    "svc = svm.SVC()\n",
    "clf = GridSearchCV(svc, parameters)\n",
    "grid_result = clf.fit(df_x, df_y_new)\n",
    "#GridSearchCV(estimator=SVC(),\n",
    "#             param_grid={'C': [1, 10], 'kernel': ('linear', 'rbf')})\n",
    "#sorted(clf.cv_results_.keys())\n",
    "print('Best Score: ', grid_result.best_score_)\n",
    "print('Best Params: ', grid_result.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 475,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "clf = SVC(kernel='rbf', C = 10)\n",
    "clf.fit(df_x,df_y_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate hue_mean, hue_std, saturation_mean, saturation_std, value_mean, value_std of the first 400 images\n",
    "new_feature = []\n",
    "for i in range(100):\n",
    "    new_feature.append(RGB_HSV_converter('test_x',i))\n",
    "# create the pandas DataFrame\n",
    "df_x_test = pd.DataFrame(new_feature, columns = ['hue_mean', 'hue_std', 'saturation_mean', 'saturation_std', 'value_mean', 'value_std', 'NIR_mean', 'NIR_std'])\n",
    "# print dataframe\n",
    "# df_x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 1, 4, 1, 3, 4, 4, 4, 4, 1, 4, 4, 4, 1, 4, 1, 1, 4, 4, 4, 1, 4,\n",
       "       4, 1, 2, 1, 3, 4, 4, 3, 1, 4, 2, 4, 3, 1, 4, 3, 1, 1, 4, 4, 4, 4,\n",
       "       4, 1, 1, 4, 1, 4, 4, 1, 1, 3, 2, 2, 4, 4, 2, 2, 3, 4, 1, 4, 2, 1,\n",
       "       4, 3, 4, 4, 4, 1, 4, 4, 4, 4, 4, 4, 4, 2, 4, 2, 4, 4, 4, 4, 1, 1,\n",
       "       3, 4, 4, 1, 3, 4, 4, 4, 1, 4, 4, 4])"
      ]
     },
     "execution_count": 477,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normalize the training data\n",
    "#from sklearn import preprocessing\n",
    "# Get column names first\n",
    "#names = df_x_test.columns\n",
    "# Create the Scaler object\n",
    "#scaler = preprocessing.MinMaxScaler()\n",
    "# Fit your data on the scaler object\n",
    "#scaled_df_x_test = scaler.fit_transform(df_x_test)\n",
    "#scaled_df_x_test = pd.DataFrame(scaled_df_x_test, columns=names)\n",
    "#scaled_df_x_test\n",
    "y_pred = clf.predict(df_x_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     1\n",
       "1     1\n",
       "2     4\n",
       "3     3\n",
       "4     3\n",
       "5     2\n",
       "6     1\n",
       "7     1\n",
       "8     4\n",
       "9     1\n",
       "10    4\n",
       "11    2\n",
       "12    2\n",
       "13    2\n",
       "14    4\n",
       "15    1\n",
       "16    3\n",
       "17    2\n",
       "18    4\n",
       "19    2\n",
       "20    1\n",
       "21    4\n",
       "22    1\n",
       "23    1\n",
       "24    2\n",
       "25    1\n",
       "26    1\n",
       "27    4\n",
       "28    4\n",
       "29    4\n",
       "     ..\n",
       "70    2\n",
       "71    3\n",
       "72    4\n",
       "73    4\n",
       "74    3\n",
       "75    2\n",
       "76    4\n",
       "77    4\n",
       "78    2\n",
       "79    4\n",
       "80    4\n",
       "81    2\n",
       "82    2\n",
       "83    2\n",
       "84    4\n",
       "85    4\n",
       "86    1\n",
       "87    1\n",
       "88    2\n",
       "89    4\n",
       "90    2\n",
       "91    1\n",
       "92    3\n",
       "93    4\n",
       "94    4\n",
       "95    2\n",
       "96    1\n",
       "97    4\n",
       "98    4\n",
       "99    4\n",
       "Length: 100, dtype: int64"
      ]
     },
     "execution_count": 478,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# restruct train_y array by transposition\n",
    "new_feature_y = []\n",
    "for i in range(100):\n",
    "    new_feature_y.append(annots['test_y'][:,i])\n",
    "# create the pandas DataFrame\n",
    "df_y_test = pd.DataFrame(new_feature_y, columns = ['barren_land', 'trees', 'grassland', 'none'])\n",
    "y_true = df_y_test['barren_land']*1+df_y_test['trees']*2+df_y_test['grassland']*3+df_y_test['none']*4\n",
    "y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.62"
      ]
     },
     "execution_count": 479,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.826  4000,1000, 6 feature, kernel = linear\n",
    "# 0.8491 40000,10000, 6 feature, kernel = linear\n",
    "# 0.915 4000,1000, 8 feature, kernel = linear\n",
    "# 0.871 4000,1000, 8 feature, kernel = rbf\n",
    "# 0.372 4000,1000, 8 feature, kernel = rbf, normalize"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
